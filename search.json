[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About MLJ",
    "section": "",
    "text": "MLJ(Machine Learning in Julia) 参见 Blaom et al. (2020), 是使用Julia语言的机器学习集成工具箱,类似Python 的 scikit-learn,其中包括 180多种原生Julia 语言模型, 同时也包括了大量的scikit-learn 模型"
  },
  {
    "objectID": "index.html#浏览mlj-model",
    "href": "index.html#浏览mlj-model",
    "title": "About MLJ",
    "section": "1. 浏览MLJ Model",
    "text": "1. 浏览MLJ Model\n由于导入的模型非常多, 所以dev版文档 提供了快速浏览模型内容,按照机器学习的类型进行划分"
  },
  {
    "objectID": "index.html#mlj-workflow",
    "href": "index.html#mlj-workflow",
    "title": "About MLJ",
    "section": "2. MLJ workflow",
    "text": "2. MLJ workflow\n\nimport data\nmodel search\nInstantiating a model\nEvaluating a model\nperformance evaluation\n\n基本上所有的 quarto note 都遵循这个流程"
  },
  {
    "objectID": "category/dimension-reduction/1-nci60-pca-svm.html",
    "href": "category/dimension-reduction/1-nci60-pca-svm.html",
    "title": "1-nci60-pca-clustering-svm",
    "section": "",
    "text": "简介\n\n\n\n参见 [ISLR-nci60]:An Introduction to Statistical Learning.pdf page 18\n流程为:pca-&gt;clustering-&gt;svm 半监督学习方法,首先对数据降维, 然后聚类, 最后使用 SVM 进行分类学习"
  },
  {
    "objectID": "category/dimension-reduction/1-nci60-pca-svm.html#load-package",
    "href": "category/dimension-reduction/1-nci60-pca-svm.html#load-package",
    "title": "1-nci60-pca-clustering-svm",
    "section": "1. load package",
    "text": "1. load package\n\n\nCode\nimport MLJ:transform,predict\nusing DataFrames,MLJ,CSV,MLJModelInterface,GLMakie,Random\nRandom.seed!(45454)\n\n\nWARNING: using DataFrames.transform in module Main conflicts with an existing identifier.\n\n\nTaskLocalRNG()"
  },
  {
    "objectID": "category/dimension-reduction/1-nci60-pca-svm.html#import-data",
    "href": "category/dimension-reduction/1-nci60-pca-svm.html#import-data",
    "title": "1-nci60-pca-clustering-svm",
    "section": "2. import data",
    "text": "2. import data\n\n\nCode\n    df= CSV.File(\"./data/NCI60.csv\") |&gt; DataFrame |&gt; dropmissing\n    Xtr = df[:,2:end]\n    Xtr_labels = Vector(df[:,1])\n    # # split other half to testing set\n    Xte=df[1:3:end,2:end]\n    Xte_labels = Vector(df[1:3:end,1])\n    first(df,10)\n\n\n10×6831 DataFrame6731 columns omitted\n\n\n\nRow\nColumn1\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n⋯\n\n\n\nString3\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\n⋯\n\n\n\n\n1\nV1\n0.3\n1.18\n0.55\n1.14\n-0.265\n-0.07\n0.35\n-0.315\n-0.45\n-0.65498\n-0.65\n-0.94\n0.31\n0.0150098\n-0.08\n-2.37\n-0.54\n-0.615\n0.0\n-0.51999\n-0.37\n-0.29\n-0.17499\n0.07\n-0.04\n0.025\n-0.74\n-0.47999\n-0.45\n-0.93\n0.16\n-0.55\n-0.55001\n0.055\n-0.37\n-0.165\n0.21\n0.47\n0.0\n-2.60208e-18\n0.139981\n-0.215\n-0.065\n-0.225\n-0.35\n-1.335\n0.0\n0.2175\n0.25\n0.13\n-0.48\n-0.42\n-0.7\n-0.275\n-0.34499\n-0.16\n-0.35\n0.555\n0.29\n-0.27\n-0.339981\n0.305\n-0.005\n0.7\n0.45002\n0.21\n0.29\n0.0849902\n-0.45501\n0.12\n-0.66\n0.1\n0.1\n-0.099961\n-0.399981\n-0.195\n0.28\n2.36\n0.47\n0.18\n-0.64499\n1.3\n0.0\n-0.48\n0.595\n-0.0599805\n0.055\n0.0975\n0.4\n0.28\n0.76\n1.425\n-0.51\n0.94\n0.94\n0.68\n-0.21\n-1.19\n0.0\n⋯\n\n\n2\nV2\n0.679961\n1.28996\n0.169961\n0.379961\n0.464961\n0.579961\n0.699961\n0.724961\n-0.040039\n-0.285019\n-0.310039\n-0.720039\n-0.010039\n0.0\n-0.570039\n0.0\n-0.470039\n-0.355039\n0.00498051\n-0.480029\n-0.140039\n-0.090039\n0.00497074\n-0.220039\n-0.370039\n0.0\n-0.320039\n0.159971\n0.179961\n-0.320039\n-0.440039\n0.349961\n0.449951\n0.104961\n0.489961\n0.204961\n-0.050039\n-0.010039\n0.269961\n0.019961\n0.0499415\n-0.315039\n-0.325039\n-0.055039\n-0.280039\n-0.255039\n0.229961\n-0.342539\n-0.560039\n-0.900039\n-0.060039\n-0.200039\n-0.670039\n0.324961\n0.134971\n0.539961\n0.229961\n0.084961\n-0.080039\n0.949961\n0.93998\n0.194961\n1.90496\n0.499961\n0.349981\n0.899961\n1.21996\n0.0\n0.374951\n0.279961\n-3.89862e-5\n-0.090039\n-0.050039\n0.0\n0.90998\n0.274961\n-0.040039\n0.869961\n-0.100039\n1.40996\n1.00497\n0.779961\n-0.110039\n-0.350039\n-0.215039\n-0.0600195\n0.324961\n0.267461\n0.129961\n0.229961\n0.079961\n0.514961\n-0.420039\n-0.350039\n-0.790039\n-0.290039\n-0.010039\n-1.05004\n-2.04004\n⋯\n\n\n3\nV3\n0.94\n-0.04\n-0.17\n-0.04\n-0.605\n0.0\n0.09\n0.645\n0.43\n0.475019\n0.41\n0.13\n-0.35\n0.0\n0.0\n0.0\n-0.8\n0.0\n-0.00498051\n0.0\n-0.14\n0.05\n-0.0649903\n-0.06\n0.29\n0.715\n-0.07\n-0.0899903\n-0.31\n0.58\n-0.48\n0.23\n-0.0400098\n-0.935\n-0.75\n-0.385\n-0.34\n0.12\n-0.47\n0.17\n-0.86002\n-0.175\n-0.715\n-0.965\n-0.54\n-0.005\n-0.06\n-0.7225\n-0.92\n0.47\n0.7\n0.67\n-0.9\n-0.265\n-0.42499\n-0.24\n-0.03\n0.215\n0.29\n0.07\n0.12002\n0.515\n0.545\n-0.03\n0.19002\n-0.07\n0.4\n0.0\n-0.0950098\n0.27\n0.08\n0.0\n0.0\n-0.319961\n0.0900195\n0.105\n-0.28\n1.99\n0.0\n0.87\n0.0\n0.74\n0.0\n-1.2\n-0.335\n0.630019\n0.345\n0.6975\n0.27\n-0.02\n0.0\n-0.115\n-0.44\n0.54\n0.49\n0.64\n0.66\n0.0\n0.0\n⋯\n\n\n4\nV4\n0.28\n-0.31\n0.68\n-0.81\n0.625\n-1.38778e-17\n0.17\n0.245\n0.02\n0.0950195\n-0.01\n-0.12\n-0.21\n0.0\n0.61\n-1.02\n-0.47\n0.0\n-0.76498\n0.0\n-0.31\n-0.62\n-0.28499\n-0.54\n-0.52\n-0.135\n-0.89\n-0.26999\n-0.84\n-0.23\n0.32\n0.0\n0.10999\n0.455\n-0.34\n-0.895\n-1.08\n-0.43\n-0.03\n-0.13\n-0.540019\n-1.225\n-1.265\n-1.415\n-0.27\n-0.705\n-0.22\n-0.5025\n-0.04\n-0.15\n-0.16\n-0.29\n-0.18\n-0.665\n-0.77499\n0.21\n-0.77\n-0.605\n-0.19\n0.17\n-0.20998\n-0.615\n0.165\n-0.19\n0.0\n-0.06\n-0.01\n-0.50501\n-0.77501\n-0.29\n-0.71\n-0.45\n-0.61\n-0.809961\n-1.53998\n-1.035\n0.0\n3.6\n0.0\n0.85\n-0.19499\n-1.21\n1.02\n0.66\n0.775\n-0.279981\n-0.245\n-0.5025\n-0.8\n-0.75\n0.06\n-1.075\n0.54\n0.16\n0.0\n0.23\n-0.74\n0.0\n-2.5\n⋯\n\n\n5\nV5\n0.485\n-0.465\n0.395\n0.905\n0.2\n-0.005\n0.085\n0.11\n0.235\n1.49002\n0.685\n0.605\n0.355\n1.22001\n2.425\n0.0\n-0.315\n0.31\n-0.519981\n-0.0749902\n-0.865\n-0.455\n-0.49999\n-0.245\n-0.235\n-0.33\n0.0\n0.0150097\n-0.105\n-0.225\n-0.105\n-0.275\n-0.57501\n-0.45\n-0.465\n-0.39\n-0.995\n-0.355\n0.0\n-0.475\n-0.38502\n-0.77\n-0.96\n-0.97\n-0.895\n-0.63\n-0.535\n-0.8875\n-0.945\n-0.535\n0.005\n0.185\n-0.105\n-0.34\n-0.19999\n-0.665\n-0.225\n-0.41\n-0.215\n-0.175\n-0.784981\n-0.33\n-0.39\n-0.075\n-0.20498\n-0.325\n-0.485\n-0.35001\n-0.23001\n-0.155\n-0.575\n-0.615\n-0.695\n-0.634961\n-1.09498\n-1.0\n-0.335\n-1.385\n0.345\n0.815\n0.56001\n-0.155\n0.0\n-1.195\n-0.16\n-0.10498\n0.0\n-0.0075\n-0.945\n-0.965\n-0.225\n-0.46\n0.045\n0.795\n1.305\n0.705\n0.055\n0.715\n0.925\n⋯\n\n\n6\nV6\n0.31\n-0.03\n-0.1\n-0.46\n-0.205\n-0.54\n-0.64\n-0.585\n-0.77\n-0.24498\n-0.12\n0.0\n-0.69\n-0.73499\n-0.67\n-0.05\n0.09\n-0.805\n0.59502\n-0.42999\n-0.85\n-0.09\n-0.0149903\n0.0\n0.15\n0.805\n-0.7\n0.36001\n-0.16\n0.04\n-0.17\n0.09\n0.0599902\n-0.635\n-0.51\n-0.585\n0.72\n-0.17\n-0.55\n0.21\n-0.13002\n0.125\n-0.415\n-0.475\n-0.02\n-0.405\n-0.4\n0.0475\n0.22\n-1.4\n-0.65\n-0.65\n-0.15\n-0.475\n-0.51499\n0.0\n-0.35\n-0.755\n-0.54\n-1.16\n-1.70998\n-0.415\n-1.275\n-0.89\n-0.269981\n-1.18\n-1.89\n-1.93501\n-2.56501\n-2.5\n-1.01\n-0.75\n-0.85\n-0.589961\n0.0\n-0.085\n0.18\n1.37\n-0.15\n-2.84\n0.0\n-1.74\n-1.38\n-2.62\n-0.715\n-0.819981\n-0.545\n-0.5525\n-0.76\n-1.02\n-1.71\n-0.495\n-0.76\n-0.28\n-0.39\n-0.5\n-0.53\n-0.85\n-0.38\n⋯\n\n\n7\nV7\n-0.83\n0.0\n0.13\n-1.63\n0.075\n-0.36\n0.1\n0.155\n-0.29\n-0.0849805\n-0.01\n-0.24\n-0.44\n0.0\n0.0\n0.0\n-0.38\n0.495\n0.0\n0.43001\n0.31\n0.09\n-0.30499\n-0.24\n-0.58\n0.445\n-0.28\n0.37001\n0.0\n-0.27\n-0.12\n0.05\n0.00999023\n-0.195\n-0.86\n-0.405\n-0.6\n-0.27\n-0.54\n0.19\n-0.0100195\n-0.465\n-1.375\n-0.945\n-0.31\n-0.435\n-0.1\n-0.8725\n-0.74\n-2.66\n-2.02\n-1.52\n-1.33\n-0.555\n-0.84499\n-0.76\n-0.84\n-0.735\n-0.37\n-0.95\n-1.14998\n-1.185\n-1.485\n-0.58\n-0.0299805\n-1.26\n-1.25\n-0.0450098\n-1.08501\n-0.08\n-0.44\n-0.1\n-0.28\n-0.269961\n0.0900195\n-0.335\n-0.17\n-0.48\n0.05\n-1.12\n-0.58499\n-1.93\n0.0\n-1.29\n-0.875\n-1.62998\n-0.755\n-0.8325\n-0.73\n-0.47\n-0.69\n-1.145\n-1.6\n-0.58\n-1.39\n-0.62\n-0.15\n-0.79\n-0.83\n⋯\n\n\n8\nV8\n-0.19\n-0.87\n-0.45\n0.08\n0.005\n0.35\n-0.04\n-0.265\n-0.31\n-0.24498\n-0.91\n-1.23\n-0.52\n-0.26499\n-0.48\n-1.4\n-0.19\n0.125\n-0.51498\n-0.83999\n-0.72\n-0.32\n-0.59499\n-0.34\n-0.82\n0.0\n-1.18\n-0.32999\n-0.69\n-1.67\n1.3\n0.0\n-0.43001\n-0.685\n-1.55\n-0.955\n-0.74\n-0.2\n-0.58\n0.01\n-0.44002\n-0.055\n-0.565\n-0.795\n-0.8\n-0.345\n-0.37\n-0.2725\n-0.71\n-0.21\n-0.32\n-0.3\n-0.92\n-0.115\n0.0150098\n0.13\n0.13\n0.475\n-0.57\n-0.07\n-0.389981\n-0.185\n-1.055\n0.15\n-0.18998\n0.84\n0.84\n0.73499\n0.18499\n0.21\n-0.48\n-0.28\n0.12\n0.100039\n-0.389981\n-0.715\n0.14\n-0.82\n-0.47\n-1.64\n0.0\n0.0\n0.0\n-0.4\n-0.335\n0.11002\n-0.125\n0.0675\n-0.77\n-0.65\n-0.43\n1.215\n0.4\n-0.7\n-1.79\n-1.13\n-0.07\n0.53\n0.21\n⋯\n\n\n9\nV9\n0.46\n0.0\n1.15\n-1.4\n-0.005\n-0.7\n-0.92\n-0.515\n-0.28\n-0.11498\n-0.17\n-0.4\n-0.52\n-0.23499\n2.21\n-2.44\n0.26\n0.155\n0.135019\n-0.90999\n-0.13\n-0.4\n-0.29499\n0.16\n-0.23\n-0.315\n0.51\n0.20001\n-0.19\n0.09\n-0.85\n-0.78\n-1.05001\n0.005\n-1.06\n-0.425\n-0.76\n-0.27\n-0.96\n-1.26\n-1.05002\n-0.835\n-1.705\n-1.195\n-1.24\n-1.065\n0.04\n-0.0225\n-0.48\n-0.46\n0.22\n0.46\n0.56\n0.335\n0.35501\n0.39\n0.18\n-0.055\n-0.11\n0.46\n0.46002\n-0.005\n0.445\n-0.52\n-0.339981\n-0.01\n-0.55\n0.17499\n-0.41501\n-0.18\n0.05\n3.44234e-18\n0.0\n-0.249961\n0.360019\n0.195\n-0.3\n-0.77\n-0.37\n-0.34\n-0.45499\n-0.82\n0.0\n-0.7\n0.145\n0.0200195\n-0.155\n-0.1825\n0.74\n0.52\n0.05\n-0.105\n-0.54\n0.0\n0.53\n0.21\n0.0\n0.0\n1.36\n⋯\n\n\n10\nV10\n0.76\n1.49\n0.28\n0.1\n-0.525\n0.36\n0.6\n0.175\n0.58\n1.14502\n1.75\n1.71\n0.51\n0.66501\n-0.1\n-0.24\n-0.69\n-0.115\n0.235019\n0.89001\n0.3\n0.08\n0.12501\n0.32\n1.28\n0.895\n1.35\n0.42001\n0.37\n0.45\n-0.25\n-0.01\n-0.27001\n-0.455\n0.61\n0.615\n0.41\n0.2\n0.13\n0.7\n-0.12002\n-0.135\n-0.235\n0.475\n0.04\n-0.295\n1.05\n1.1275\n0.74\n-0.26\n-0.09\n0.15\n-0.09\n-0.265\n0.15501\n-0.23\n0.25\n0.095\n0.36\n-0.08\n-0.12998\n0.205\n0.985\n0.42\n0.32002\n0.25\n0.19\n0.21499\n0.0449902\n-0.2\n-0.31\n0.0\n-0.41\n-0.00996101\n0.19002\n0.095\n0.0\n1.94\n0.14\n-0.18\n-0.58499\n-0.42\n-0.38\n-1.52\n-0.745\n-0.55998\n-0.285\n-0.2025\n-0.05\n0.35\n0.03\n0.755\n0.8\n1.52\n2.11\n0.91\n-0.25\n-0.56\n-0.77\n⋯"
  },
  {
    "objectID": "category/dimension-reduction/1-nci60-pca-svm.html#mlj-workflow",
    "href": "category/dimension-reduction/1-nci60-pca-svm.html#mlj-workflow",
    "title": "1-nci60-pca-clustering-svm",
    "section": "2. MLJ WorkFlow",
    "text": "2. MLJ WorkFlow\n\n2.1 define models\n需要定义三个模型:\n\npca model\nclustering model\nclassficiation model\n\n\n\nCode\n PCA = @load PCA pkg=MultivariateStats\n KMeans = @load KMeans pkg=Clustering\n SVC = @load SVC pkg=LIBSVM\n\n model=PCA(maxoutdim=2) # pca model\n model2 = KMeans(k=3)   # clustering model\n model3 = SVC()        # svm dodel\n\n\n[ Info: For silent loading, specify `verbosity=0`. \n[ Info: For silent loading, specify `verbosity=0`. \n[ Info: For silent loading, specify `verbosity=0`. \n\n\nimport MLJMultivariateStatsInterface ✔\nimport MLJClusteringInterface ✔\nimport MLJLIBSVMInterface ✔\n\n\nSVC(\n  kernel = LIBSVM.Kernel.RadialBasis, \n  gamma = 0.0, \n  cost = 1.0, \n  cachesize = 200.0, \n  degree = 3, \n  coef0 = 0.0, \n  tolerance = 0.001, \n  shrinking = true)\n\n\n\n\n2.2 PCA\n在 PCA 流程中要完成两步:\n\nPCA 模型训练(如果为了便于可视化, 维度为 2或者 3)\n将原始数据映射到降维的空间上\n\n\n\nCode\nmach = machine(model, Xtr) |&gt; fit!\nXproj =transform(mach, Xtr)\nfirst(Xproj,10)\n\n\n[ Info: Training machine(PCA(maxoutdim = 2, …), …).\n\n\n10×2 DataFrame\n\n\n\nRow\nx1\nx2\n\n\n\nFloat64\nFloat64\n\n\n\n\n1\n-19.7958\n0.115269\n\n\n2\n-21.5461\n-1.45735\n\n\n3\n-25.0566\n1.52609\n\n\n4\n-37.4095\n-11.3895\n\n\n5\n-50.2186\n-1.34617\n\n\n6\n-26.4352\n0.462982\n\n\n7\n-27.3393\n2.65031\n\n\n8\n-21.4897\n4.95414\n\n\n9\n-20.8525\n10.1631\n\n\n10\n-26.9529\n21.4733\n\n\n\n\n\n\n\n\n2.3 生成决策边界测试数据集\n\n\nCode\nfunction boundary_data(df,;n=200)\n    n1=n2=n\n    xlow,xhigh=extrema(df[:,:x1])\n    ylow,yhigh=extrema(df[:,:x2])\n    tx = range(xlow,xhigh; length=n1)\n    ty = range(ylow,yhigh; length=n2)\n    x_test = mapreduce(collect, hcat, Iterators.product(tx, ty));\n    xtest=MLJ.table(x_test')\n    return tx,ty, xtest\nend\ntx,ty, xtest=boundary_data(Xproj)  #xtest  生成决策边界的数据\n\n\n(-50.21864152783379:0.5383986285981281:56.9226855631937, -51.362711708066826:0.3660101806028475:21.473314231899835, Tables.MatrixTable{LinearAlgebra.Adjoint{Float64, Matrix{Float64}}} with 40000 rows, 2 columns, and schema:\n :x1  Float64\n :x2  Float64)\n\n\n\n\n2.5 Clustering and SVM training\n\n\nCode\n mach2= machine(model2, Xproj) |&gt; fit!\n yhat = predict(mach2, Xproj)  # 聚类结果\n cat=yhat|&gt;Array|&gt;levels\n\n mach3 = machine(model3, Xproj, yhat)|&gt;fit!\n ypred=predict(mach3, xtest)|&gt;Array|&gt;d-&gt;reshape(d,200,200) #SVM 结果\n\n\n[ Info: Training machine(KMeans(k = 3, …), …).\n[ Info: Training machine(SVC(kernel = RadialBasis, …), …).\n\n\n200×200 Matrix{Int64}:\n 1  1  1  1  1  1  1  1  1  1  1  1  1  …  1  1  1  1  1  1  1  1  1  1  1  1\n 1  1  1  1  1  1  1  1  1  1  1  1  1     1  1  1  1  1  1  1  1  1  1  1  1\n 1  1  1  1  1  1  1  1  1  1  1  1  1     1  1  1  1  1  1  1  1  1  1  1  1\n 1  1  1  1  1  1  1  1  1  1  1  1  1     1  1  1  1  1  1  1  1  1  1  1  1\n 1  1  1  1  1  1  1  1  1  1  1  1  1     1  1  1  1  1  1  1  1  1  1  1  1\n 1  1  1  1  1  1  1  1  1  1  1  1  1  …  1  1  1  1  1  1  1  1  1  1  1  1\n 1  1  1  1  1  1  1  1  1  1  1  1  1     1  1  1  1  1  1  1  1  1  1  1  1\n 1  1  1  1  1  1  1  1  1  1  1  1  1     1  1  1  1  1  1  1  1  1  1  1  1\n 1  1  1  1  1  1  1  1  1  1  1  1  1     1  1  1  1  1  1  1  1  1  1  1  1\n 1  1  1  1  1  1  1  1  1  1  1  1  1     1  1  1  1  1  1  1  1  1  1  1  1\n 1  1  1  1  1  1  1  1  1  1  1  1  1  …  1  1  1  1  1  1  1  1  1  1  1  1\n 1  1  1  1  1  1  1  1  1  1  1  1  1     1  1  1  1  1  1  1  1  1  1  1  1\n 1  1  1  1  1  1  1  1  1  1  1  1  1     1  1  1  1  1  1  1  1  1  1  1  1\n ⋮              ⋮              ⋮        ⋱        ⋮              ⋮           \n 3  3  3  3  3  3  3  3  3  3  3  3  3     3  3  3  3  3  3  3  3  3  3  3  3\n 3  3  3  3  3  3  3  3  3  3  3  3  3     3  3  3  3  3  3  3  3  3  3  3  3\n 3  3  3  3  3  3  3  3  3  3  3  3  3  …  3  3  3  3  3  3  3  3  3  3  3  3\n 3  3  3  3  3  3  3  3  3  3  3  3  3     3  3  3  3  3  3  3  3  3  3  3  3\n 3  3  3  3  3  3  3  3  3  3  3  3  3     3  3  3  3  3  3  3  3  3  3  3  3\n 3  3  3  3  3  3  3  3  3  3  3  3  3     3  3  3  3  3  3  3  3  3  3  3  3\n 3  3  3  3  3  3  3  3  3  3  3  3  3     3  3  3  3  3  3  3  3  3  3  3  3\n 3  3  3  3  3  3  3  3  3  3  3  3  3  …  3  3  3  3  3  3  3  3  3  3  3  3\n 3  3  3  3  3  3  3  3  3  3  3  3  3     3  3  3  3  3  3  3  3  3  3  3  3\n 3  3  3  3  3  3  3  3  3  3  3  3  3     3  3  3  3  3  3  3  3  3  3  3  3\n 3  3  3  3  3  3  3  3  3  3  3  3  3     3  3  3  3  3  3  3  3  3  3  3  3\n 3  3  3  3  3  3  3  3  3  3  3  3  3     3  3  3  3  3  3  3  3  3  3  3  3\n\n\n\n\n2.6 plot results\n\n\nCode\n    function plot_model()\n        fig = Figure()\n        ax = Axis(fig[1, 1],title=\"NCI60 Machine Learning\",subtitle=\"pca-&gt;clustering-&gt;svm\")\n\n        colors = [:red, :orange, :blue]\n        contourf!(ax, tx,ty,ypred)\n        for (i, c) in enumerate(Array(yhat))\n            data = Xproj[i, :]\n            \n            scatter!(ax, data.x1, data.x2;marker=:circle,markersize=12,color=(colors[c],0.3),strokewidth=1,strokecolor=:black)\n            text!(ax,data.x1, data.x2;text=\"v$(i)\")\n        end\n\n        fig\n        #save(\"NCI60 Machine Learning:pca-&gt;clustering-&gt;svm-with-tag.png\",fig)\n    end\n\n    plot_model()"
  },
  {
    "objectID": "category/dimension-reduction/2-olivetti-face-intro.html#dataprocessing.jl",
    "href": "category/dimension-reduction/2-olivetti-face-intro.html#dataprocessing.jl",
    "title": "2-olivetti-face-project",
    "section": "1. dataprocessing.jl",
    "text": "1. dataprocessing.jl\n读取 csv 文件, 返回 返回 olivetti face 训练数据,测试数据和标签 load_olivetti_faces 函数返回训练,测试数据集和对应标签\n(Xtrain, Xtest), (ytrain, ytest)=load_olivetti_faces()"
  },
  {
    "objectID": "category/dimension-reduction/2-olivetti-face-intro.html#trainsave-model.jl",
    "href": "category/dimension-reduction/2-olivetti-face-intro.html#trainsave-model.jl",
    "title": "2-olivetti-face-project",
    "section": "2. train&save-model.jl",
    "text": "2. train&save-model.jl\n导入数据,返回一个高阶函数make_model make_model 函数首先接受训练数据集, 然后等待 dim 需要缩减到的维度参数\n最终训练的模型保存的对应的 jlso 文件中:JLSO.save(\"$(pwd())/models/of-model-$(dim)pcs.jlso\",:pca=&gt;mach)\nfunction  make_model(Xtr)\n    return (dim)-&gt;begin\n        model = PCA(maxoutdim=dim)\n        mach = machine(model, Xtr) |&gt; fit!\n        try\n            JLSO.save(\"$(pwd())/models/of-model-$(dim)pcs.jlso\",:pca=&gt;mach)\n            @info \"$(dim) dimension pca model saved\"\n        catch e\n            @warn \"$(e) has problem\"\n        end\n    end\nend\n\nmake_ol_model=make_model(Xtrain)\n#make_ol_model.([10,20,150])"
  },
  {
    "objectID": "category/dimension-reduction/2-olivetti-face-intro.html#transform-reconstruct-methods",
    "href": "category/dimension-reduction/2-olivetti-face-intro.html#transform-reconstruct-methods",
    "title": "2-olivetti-face-project",
    "section": "3-transform-reconstruct-methods",
    "text": "3-transform-reconstruct-methods\n在 MLJ.jl的 pca 方法和 MultiVariate.jl 的方法稍有不同, 使用的是 transform函数,而不是project方法\n主要函数为transform_to_pcadata1,为高阶函数 输入参数dim 为需要缩减到的维度 函数内部调用第2 步获得的模型 返回一个函数 等待 df 参数 内部调用transform函数对数据做降维处理 返回数据\nfunction transform_to_pcadata(dim::Int)\n    mach = JLSO.load(\"$(pwd())/models/of-model-$(dim)pcs.jlso\")[:pca]\n    return (imgs::DataFrame)-&gt;begin\n        @info \"$dim pca proceeding...\"\n        pcaX = transform(mach, imgs)     # 降维数据\n        # 返回降维数据\n        return pcaX\n    end\nend\ntransform_to_pcadata2 与transform_to_pcadata1 一样是高阶函数 但是参数输入的顺序不同, transform_to_pcadata2中先输入dataframe, 然后等待维度参数\n    function transform_to_pcadata2(imgs::DataFrame)\n        \n        return (dim::Int)-&gt;begin\n            @info \"$dim pca proceeding...\"\n            mach = JLSO.load(\"$(pwd())/models/of-model-$(dim)pcs.jlso\")[:pca]\n            pcaX = transform(mach, imgs)     # 降维数据\n            # 返回降维数据\n            return pcaX\n        end\n    end\n\n重建数据方法\n从低维度数据恢复原始维度数据, 在MLJ中使用的方法是inverse_transform reconstruct_data 方法首先从数据 dataframe 中获取维度column数据 从存储模型中调用训练模型 执行重建变换\n    \"\"\"\n        reconstruct_data(imgs::DataFrame)\n    从降维数据重建图片\n    TBW\n    \"\"\"\n    function reconstruct_data(imgs::DataFrame)\n            \n            _,cols=size(imgs)\n            @info \"imgs  reconstructing from $(cols) dimension\" \n            mach = JLSO.load(\"$(pwd())/models/of-model-$(cols)pcs.jlso\")[:pca]\n            Xr = inverse_transform(mach, imgs)  # 重建近似数据\n            return Xr\n    end"
  },
  {
    "objectID": "category/dimension-reduction/2-olivetti-face-intro.html#维度缩减到-1d-的数据",
    "href": "category/dimension-reduction/2-olivetti-face-intro.html#维度缩减到-1d-的数据",
    "title": "2-olivetti-face-project",
    "section": "维度缩减到 1d 的数据",
    "text": "维度缩减到 1d 的数据\n以 faces 为例,如果缩减到一个维度, 获得的数据是所有图片共用的最大元素,也就是所有人面部共用的特征"
  },
  {
    "objectID": "category/classification/24-classfication-comparison.html",
    "href": "category/classification/24-classfication-comparison.html",
    "title": "several classfication model comparison",
    "section": "",
    "text": "Code\n    import MLJ:predict,predict_mode\n    using  MLJ,GLMakie,DataFrames,Random\n    Random.seed!(1222)\n\n\nTaskLocalRNG()"
  },
  {
    "objectID": "category/classification/24-classfication-comparison.html#load-package",
    "href": "category/classification/24-classfication-comparison.html#load-package",
    "title": "several classfication model comparison",
    "section": "",
    "text": "Code\n    import MLJ:predict,predict_mode\n    using  MLJ,GLMakie,DataFrames,Random\n    Random.seed!(1222)\n\n\nTaskLocalRNG()"
  },
  {
    "objectID": "category/classification/24-classfication-comparison.html#make-data",
    "href": "category/classification/24-classfication-comparison.html#make-data",
    "title": "several classfication model comparison",
    "section": "2. make data",
    "text": "2. make data\n\n\nCode\n    function circle_data()\n    X, y = make_circles(400; noise=0.1, factor=0.3)\n    df = DataFrame(X)\n    df.y = y\n    return df\n    end\n    function moons_data()\n        X, y = make_moons(400; noise=0.1)\n        df = DataFrame(X)\n        df.y = y\n        return df\n    end\n    function blob_data()\n        X, y = make_blobs(400, 2; centers=2, cluster_std=[1.0, 2.0])\n        df = DataFrame(X)\n        df.y = y\n        return df\n    end\n    #cat=df1.y|&gt;levels|&gt;unique\n    colors=[:green, :purple]\n\n\n2-element Vector{Symbol}:\n :green\n :purple"
  },
  {
    "objectID": "category/classification/24-classfication-comparison.html#define-function",
    "href": "category/classification/24-classfication-comparison.html#define-function",
    "title": "several classfication model comparison",
    "section": "3. define function",
    "text": "3. define function\n\n\nCode\nfunction plot_origin_data(df)\n    fig=Figure()\n    ax=Axis(fig[1,1])\n    local cat=df.y|&gt;levels|&gt;unique\n    \n    local colors=[:green, :purple]\n    for (i,c) in enumerate(cat)\n        d=df[y.==c,:]\n        scatter!(ax, d[:,1],d[:,2],color=(colors[i],0.6))\n        #@show d\n    end\n    fig\nend\n\nnums=100\nfunction boundary_data(df,;n=nums)\n    n1=n2=n\n    xlow,xhigh=extrema(df[:,:x1])\n    ylow,yhigh=extrema(df[:,:x2])\n    tx = LinRange(xlow,xhigh,n1)\n    ty = LinRange(ylow,yhigh,n2)\n    x_test = mapreduce(collect, hcat, Iterators.product(tx, ty));\n    x_test=MLJ.table(x_test')\n    return tx,ty,x_test\nend\n\nfunction plot_desc_boudary(fig,ytest,i;df=df1,row=1)\n        tx,ty,xs,ys, xtest=boundary_data(df)\n        local ax=Axis(fig[row,i],title=\"$(names[i])\")\n\n        contourf!(ax, tx,ty,ytest,levels=length(cat),colormap=:phase)\n\n        for (i,c) in enumerate(cat)\n            d=df[y.==c,:]\n            scatter!(ax, d[:,1],d[:,2],color=(colors[i],0.6))\n        end\n        hidedecorations!(ax)\nend\n\n\nplot_desc_boudary (generic function with 1 method)"
  },
  {
    "objectID": "category/classification/24-classfication-comparison.html#define-machine-learning-models",
    "href": "category/classification/24-classfication-comparison.html#define-machine-learning-models",
    "title": "several classfication model comparison",
    "section": "4. define machine learning models",
    "text": "4. define machine learning models\n\n\nCode\n    using CatBoost.MLJCatBoostInterface\n    SVC = @load SVC pkg=LIBSVM   \n    KNNClassifier = @load KNNClassifier pkg=NearestNeighborModels\n    DecisionTreeClassifier = @load DecisionTreeClassifier pkg=DecisionTree\n    RandomForestClassifier = @load RandomForestClassifier pkg=DecisionTree\n    CatBoostClassifier = @load CatBoostClassifier pkg=CatBoost\n    BayesianLDA = @load BayesianLDA pkg=MultivariateStats\n    Booster = @load AdaBoostStumpClassifier pkg=DecisionTree\n    \n    models=[KNNClassifier,DecisionTreeClassifier,RandomForestClassifier,CatBoostClassifier,BayesianLDA,SVC]\n    names=[\"KNN\",\"DecisionTree\",\"RandomForest\",\"CatBoost\",\"BayesianLDA\",\"SVC\"]\n   function _fit(df::DataFrame,m)\n    X,y=df[:,1:2],df[:,3]\n    _,_,xtest=boundary_data(df;n=nums)\n    local predict= m==MLJLIBSVMInterface.SVC  ? MLJ.predict : MLJ.predict_mode \n    model=m()\n   mach = machine(model, X, y)|&gt;fit!\n   yhat=predict(mach, xtest)\n   ytest=yhat|&gt;Array|&gt;d-&gt;reshape(d,nums,nums)\n   return  ytest\nend\n\n\n\nfunction plot_desc_boudary(fig,ytest,i;df=df1,row=1)\n    tx,ty,_=boundary_data(df)\n    local y=df.y\n    local ax=Axis(fig[row,i],title=\"$(names[i])\")\n    cat=y|&gt;levels|&gt;unique\n    contourf!(ax, tx,ty,ytest,levels=length(cat),colormap=:redsblues)\n\n    for (i,c) in enumerate(cat)\n        d=df[y.==c,:]\n        scatter!(ax, d[:,1],d[:,2],color=(colors[i],0.6))\n    end\n    hidedecorations!(ax)\n    \n\nend\n\nfunction plot_comparsion(testdata,df;row=1)\n    \n    for (i,data) in enumerate(testdata)\n        plot_desc_boudary(fig,data,i;df=df,row=row)\n    end\n    fig\nend\n\n\n[ Info: For silent loading, specify `verbosity=0`. \n[ Info: For silent loading, specify `verbosity=0`. \n[ Info: For silent loading, specify `verbosity=0`. \n[ Info: For silent loading, specify `verbosity=0`. \n[ Info: For silent loading, specify `verbosity=0`. \n[ Info: For silent loading, specify `verbosity=0`. \n[ Info: For silent loading, specify `verbosity=0`. \n\n\nimport MLJLIBSVMInterface ✔\nimport NearestNeighborModels ✔\nimport MLJDecisionTreeInterface ✔\nimport MLJDecisionTreeInterface ✔\nimport CatBoost ✔\nimport MLJMultivariateStatsInterface ✔\nimport MLJDecisionTreeInterface ✔\n\n\nplot_comparsion (generic function with 1 method)\n\n\n\n\nCode\nfig=Figure(resolution=(2100,1000))\nfunction plot_comparsion(testdata,df,row=1)\n    \n    for i in eachindex(testdata)\n        plot_desc_boudary(fig,testdata[i],i;df=df,row=row)\n    end\n    fig\nend\n\n\n\ndf1=circle_data()\n\nytest1=[_fit(df1,m) for (i,m) in enumerate(models)]\n\ndf2=moons_data()\nytest2=[_fit(df2,m) for (i,m) in enumerate(models)]\n\ndf3=blob_data()\nytest3=[_fit(df3,m) for (i,m) in enumerate(models)]\n\ndfs=[df2,df1,df3]\nytests=[ytest2,ytest1,ytest3]\n\nfig=Figure(resolution=(2100,1000))\n\nfor (df, data,i)  in zip(dfs,ytests,[1,2,3])\n    plot_comparsion(data,df;row=i)\nend\n\nfig\n\n\n[ Info: Training machine(KNNClassifier(K = 5, …), …).\n[ Info: Training machine(DecisionTreeClassifier(max_depth = -1, …), …).\n[ Info: Training machine(RandomForestClassifier(max_depth = -1, …), …).\n[ Info: Training machine(CatBoostClassifier(iterations = 1000, …), …).\n[ Info: Training machine(BayesianLDA(method = gevd, …), …).\n[ Info: Training machine(SVC(kernel = RadialBasis, …), …).\n[ Info: Training machine(KNNClassifier(K = 5, …), …).\n[ Info: Training machine(DecisionTreeClassifier(max_depth = -1, …), …).\n[ Info: Training machine(RandomForestClassifier(max_depth = -1, …), …).\n[ Info: Training machine(CatBoostClassifier(iterations = 1000, …), …).\n[ Info: Training machine(BayesianLDA(method = gevd, …), …).\n[ Info: Training machine(SVC(kernel = RadialBasis, …), …).\n[ Info: Training machine(KNNClassifier(K = 5, …), …).\n[ Info: Training machine(DecisionTreeClassifier(max_depth = -1, …), …).\n[ Info: Training machine(RandomForestClassifier(max_depth = -1, …), …).\n[ Info: Training machine(CatBoostClassifier(iterations = 1000, …), …).\n[ Info: Training machine(BayesianLDA(method = gevd, …), …).\n[ Info: Training machine(SVC(kernel = RadialBasis, …), …)."
  },
  {
    "objectID": "category/materials.html",
    "href": "category/materials.html",
    "title": "dataset list",
    "section": "",
    "text": "Datasets\nSlides"
  },
  {
    "objectID": "category/regression/3-cricket-chirp-rate.html",
    "href": "category/regression/3-cricket-chirp-rate.html",
    "title": "3-cricket-chirp-rate",
    "section": "",
    "text": "简介\n\n\n\n\nsource1\nsource2\nsourc3\n\n\n雪树蟋蟀的鸣叫实际是大腿摩擦发出的声音, 经过数据收集,发现鸣叫的频率和环境温度正相关.\n\n经过线性拟合得到的函数为:C(t)=4.25t-157.8"
  },
  {
    "objectID": "category/regression/3-cricket-chirp-rate.html#load-pacakge",
    "href": "category/regression/3-cricket-chirp-rate.html#load-pacakge",
    "title": "3-cricket-chirp-rate",
    "section": "1. load pacakge",
    "text": "1. load pacakge\n\n\nCode\nimport FileIO:load\nimport MLJ:fit!,match,predict,table,fitted_params\nusing GLMakie, CSV,DataFrames,MLJ,FileIO\nimg=load(\"./data/snowy-cricket.jpg\");"
  },
  {
    "objectID": "category/regression/3-cricket-chirp-rate.html#process-data",
    "href": "category/regression/3-cricket-chirp-rate.html#process-data",
    "title": "3-cricket-chirp-rate",
    "section": "2. process data",
    "text": "2. process data\n\n\nCode\ndf=CSV.File(\"./data/CricketChirps.csv\") |&gt; DataFrame |&gt; dropmissing;\nX=MLJ.table(reshape(df[:,1],7,1))\ny=Vector(df[:,2])\n\ntest_X=range(extrema(df[:,1])...,50)\ntest_X=MLJ.table(reshape(test_X,50,1))\ncols=names(df)\n\n\n2-element Vector{String}:\n \"Temperature\"\n \"Chirps\""
  },
  {
    "objectID": "category/regression/3-cricket-chirp-rate.html#mlj-workflow",
    "href": "category/regression/3-cricket-chirp-rate.html#mlj-workflow",
    "title": "3-cricket-chirp-rate",
    "section": "3. MLJ workflow",
    "text": "3. MLJ workflow\n\n3.1 fitting model\n\n\nCode\n    LinearRegressor = @load LinearRegressor pkg=MLJLinearModels\n    mach = fit!(machine(LinearRegressor(), X, y))\n    report(mach)\n\n\n[ Info: For silent loading, specify `verbosity=0`. \n┌ Warning: The number and/or types of data arguments do not match what the specified model\n│ supports. Suppress this type check by specifying `scitype_check_level=0`.\n│ \n│ Run `@doc MLJLinearModels.LinearRegressor` to learn more about your model's requirements.\n│ \n│ Commonly, but non exclusively, supervised models are constructed using the syntax\n│ `machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n│ constructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n│ sample or class weights.\n│ \n│ In general, data in `machine(model, data...)` is expected to satisfy\n│ \n│     scitype(data) &lt;: MLJ.fit_data_scitype(model)\n│ \n│ In the present case:\n│ \n│ scitype(data) = Tuple{Table{AbstractVector{Continuous}}, AbstractVector{Count}}\n│ \n│ fit_data_scitype(model) = Tuple{Table{&lt;:AbstractVector{&lt;:Continuous}}, AbstractVector{Continuous}}\n└ @ MLJBase ~/.julia/packages/MLJBase/fEiP2/src/machines.jl:230\n[ Info: Training machine(LinearRegressor(fit_intercept = true, …), …).\n┌ Info: Solver: MLJLinearModels.Analytical\n│   iterative: Bool false\n└   max_inner: Int64 200\n\n\nimport MLJLinearModels ✔\n\n\n\n\n3.2 plot fitting curve\n\n\nCode\nyhat=predict(mach,test_X).|&gt;(d-&gt;round(d,digits=2))\nfunction plot_fitting_curve(df,yhat)\n    X=df[:,1]\n    test_X=range(extrema(df[:,1])...,50)\n    cols=names(df)\n    fig=Figure()\n    ax=Axis(fig[1:3,1:3];xlabel=\"$(cols[1])\",ylabel=\"$(cols[2])\",title=\"cricket-chirp\")\n    ax2 = Axis(fig[2,4],title=\"snowy-tree-cricket\")\n    scatter!(ax, X,y,markersize=16,color=(:red,0.8))\n    lines!(ax, test_X,yhat,color=:blue)\n    image!(ax2,img)\n    hidespines!(ax2)\n    hidedecorations!(ax2)\n    fig\nend\nplot_fitting_curve(df,yhat)"
  },
  {
    "objectID": "category/regression/9-poisson-reg.html",
    "href": "category/regression/9-poisson-reg.html",
    "title": "9-poisson-reg",
    "section": "",
    "text": "简介\n\n\n\n泊松回归(Poisson Regression) 是一类特殊的回归模型,相应变量是计数数据(离散正整数) 响应变量的分布遵循泊松分布\ndataset data\n数据集有两个变量, 预测变量为数学成绩(Math Score),响应变量为奖学金等级(0-6)"
  },
  {
    "objectID": "category/regression/9-poisson-reg.html#load-package",
    "href": "category/regression/9-poisson-reg.html#load-package",
    "title": "9-poisson-reg",
    "section": "1. load package",
    "text": "1. load package\n\n\nCode\n    include(\"../utils.jl\")\n    import MLJ:fit!,fitted_params,coerce\n    using GLMakie,MLJ,CSV,DataFrames,ScientificTypes"
  },
  {
    "objectID": "category/regression/9-poisson-reg.html#load-data",
    "href": "category/regression/9-poisson-reg.html#load-data",
    "title": "9-poisson-reg",
    "section": "2. load data",
    "text": "2. load data\n\n\nCode\nto_ScienceType(d)=coerce(d,:Awards=&gt; Multiclass,:MathScore=&gt;Continuous)\ndf=CSV.File(\"./data/competition_awards_data.csv\") |&gt; DataFrame|&gt;dropmissing\n \n X=MLJ.table(reshape(df[:,2],200,1))\n y=Vector(df[:,1])\n (Xtrain, Xtest), (ytrain, ytest) = partition((X, y), 0.8, rng=123, multi=true)\n first(df,10)\n\n\n10×2 DataFrame\n\n\n\nRow\nAwards\nMathScore\n\n\n\nInt64\nInt64\n\n\n\n\n1\n0\n43\n\n\n2\n0\n38\n\n\n3\n0\n41\n\n\n4\n0\n33\n\n\n5\n0\n39\n\n\n6\n0\n43\n\n\n7\n0\n35\n\n\n8\n0\n41\n\n\n9\n0\n36\n\n\n10\n0\n38"
  },
  {
    "objectID": "category/regression/9-poisson-reg.html#mlj-workflow",
    "href": "category/regression/9-poisson-reg.html#mlj-workflow",
    "title": "9-poisson-reg",
    "section": "3. MLJ Workflow",
    "text": "3. MLJ Workflow\n\n3.1 load model\n\n\nCode\n    CountRegressor = @load LinearCountRegressor pkg=GLM\n    model = CountRegressor(fit_intercept=false)\n    mach = machine(model, Xtrain, ytrain)\n    fit!(mach)\n\n\nimport MLJGLMInterface ✔\n\n\n[ Info: For silent loading, specify `verbosity=0`. \n┌ Warning: The number and/or types of data arguments do not match what the specified model\n│ supports. Suppress this type check by specifying `scitype_check_level=0`.\n│ \n│ Run `@doc GLM.LinearCountRegressor` to learn more about your model's requirements.\n│ \n│ Commonly, but non exclusively, supervised models are constructed using the syntax\n│ `machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n│ constructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n│ sample or class weights.\n│ \n│ In general, data in `machine(model, data...)` is expected to satisfy\n│ \n│     scitype(data) &lt;: MLJ.fit_data_scitype(model)\n│ \n│ In the present case:\n│ \n│ scitype(data) = Tuple{Table{AbstractVector{Count}}, AbstractVector{Count}}\n│ \n│ fit_data_scitype(model) = Union{Tuple{Table{&lt;:AbstractVector{&lt;:Continuous}}, AbstractVector{Count}}, Tuple{Table{&lt;:AbstractVector{&lt;:Continuous}}, AbstractVector{Count}, AbstractVector{&lt;:Union{Continuous, Count}}}}\n└ @ MLJBase ~/.julia/packages/MLJBase/fEiP2/src/machines.jl:230\n[ Info: Training machine(LinearCountRegressor(fit_intercept = false, …), …).\n\n\ntrained Machine; caches model-specific representations of data\n  model: LinearCountRegressor(fit_intercept = false, …)\n  args: \n    1:  Source @955 ⏎ Table{AbstractVector{Count}}\n    2:  Source @555 ⏎ AbstractVector{Count}\n\n\n\n\n3.2 predict model results\n\n\nCode\n yhat=predict_mode(mach, Xtest)|&gt;Array\n @info \"rms\"=&gt;rms(yhat,ytest)\n\n report(mach)\n\n\n[ Info: \"rms\" =&gt; 0.9486832980505138\n\n\n(stderror = [0.0013746169531615926],\n dof_residual = 160.0,\n vcov = [1.88957176791926e-6;;],\n deviance = 254.53389416397937,\n coef_table = ───────────────────────────────────────────────────────────────────\n         Coef.  Std. Error     z  Pr(&gt;|z|)    Lower 95%   Upper 95%\n───────────────────────────────────────────────────────────────────\nx1  0.00104856  0.00137462  0.76    0.4456  -0.00164564  0.00374276\n───────────────────────────────────────────────────────────────────,)"
  },
  {
    "objectID": "category/regression/2-ecommerce-linear-reg.html",
    "href": "category/regression/2-ecommerce-linear-reg.html",
    "title": "2-ecommerce-linear-reg",
    "section": "",
    "text": "简介\n\n\n\n\n通过上网浏览时间预测年花费\n\n\ndataset: kaggle ecommerce dataset\nmodel\nusing MLJLinearModels.jl 🔗"
  },
  {
    "objectID": "category/regression/2-ecommerce-linear-reg.html#load-package",
    "href": "category/regression/2-ecommerce-linear-reg.html#load-package",
    "title": "2-ecommerce-linear-reg",
    "section": "1. load package",
    "text": "1. load package\n\n\nCode\nimport MLJ:predict\nusing GLMakie, MLJ,CSV,DataFrames,StatsBase\n\n\nWARNING: using StatsBase.predict in module Main conflicts with an existing identifier."
  },
  {
    "objectID": "category/regression/2-ecommerce-linear-reg.html#process-data",
    "href": "category/regression/2-ecommerce-linear-reg.html#process-data",
    "title": "2-ecommerce-linear-reg",
    "section": "2. process data",
    "text": "2. process data\n\n\nCode\nstr=\"Ecommerce-Customers\"   \ndf=CSV.File(\"./data/Ecommerce-Customers.csv\") |&gt; DataFrame |&gt; dropmissing;\nselect!(df,4:8)\nX=df[:,1:4]|&gt;Matrix|&gt;MLJ.table\ny=Vector(df[:,5])\nfirst(df,5)\n\n\n5×5 DataFrame\n\n\n\nRow\nAvg. Session Length\nTime on App\nTime on Website\nLength of Membership\nYearly Amount Spent\n\n\n\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\n\n\n\n\n1\n34.4973\n12.6557\n39.5777\n4.08262\n587.951\n\n\n2\n31.9263\n11.1095\n37.269\n2.66403\n392.205\n\n\n3\n33.0009\n11.3303\n37.1106\n4.10454\n487.548\n\n\n4\n34.3056\n13.7175\n36.7213\n3.12018\n581.852\n\n\n5\n33.3307\n12.7952\n37.5367\n4.44631\n599.406"
  },
  {
    "objectID": "category/regression/2-ecommerce-linear-reg.html#plot-corrleation-of-variables",
    "href": "category/regression/2-ecommerce-linear-reg.html#plot-corrleation-of-variables",
    "title": "2-ecommerce-linear-reg",
    "section": "3. plot corrleation of variables",
    "text": "3. plot corrleation of variables\n\n\nCode\naxs = []\nlabel=names(df)|&gt;Array\ncolors = [:orange, :lightgreen, :purple,:lightblue,:red,:green]\n\nfig = Figure(resolution=(1400, 1400))\nax=Axis(fig[1,1])\n\nfunction plot_diag(i)\n\n    ax = Axis(fig[i, i])\n    push!(axs, ax)\n    density!(ax, df[:, i]; color=(colors[i], 0.5),\n            strokewidth=1.25, strokecolor=colors[i])\nend\n\n\nfunction plot_cor(i, j)\n    ax = Axis(fig[i, j])\n    scatter!(ax, df[:, i], df[:, j]; color=colors[j])\nend\n\n\nfunction plot_pair()\n    [(i == j ? plot_diag(i) : plot_cor(i, j)) for i in 1:5, j in 1:5]\nend\n\nfunction add_xy_label()\n    for i in 1:5\n        Axis(fig[5, i], xlabel=label[i],)\n        Axis(fig[i, 1], ylabel=label[i],)\n    end\nend\n\nfunction main()\n\n    plot_pair()\n    add_xy_label()\n    return fig\nend\n\nmain()"
  },
  {
    "objectID": "category/regression/2-ecommerce-linear-reg.html#plot-pair-variabless-cov-and-cor-matrix",
    "href": "category/regression/2-ecommerce-linear-reg.html#plot-pair-variabless-cov-and-cor-matrix",
    "title": "2-ecommerce-linear-reg",
    "section": "4. plot pair variables’s cov and cor matrix",
    "text": "4. plot pair variables’s cov and cor matrix\n\n\nCode\ndf_cov = df|&gt;Matrix|&gt;cov.|&gt; d -&gt; round(d, digits=3)\ndf_cor = df|&gt;Matrix|&gt;cor.|&gt; d -&gt; round(d, digits=3)\n\nfunction plot_cov_cor()\n    fig = Figure(resolution=(2200, 800))\n    ax1 = Axis(fig[1, 1]; xticks=(1:5, label), yticks=(1:5, label), title=\"ecommerce cov matrix\",yreversed=true)\n    ax3 = Axis(fig[1, 3], xticks=(1:5, label), yticks=(1:5, label), title=\"ecommerce cor matrix\",yreversed=true)\n\n    hm = heatmap!(ax1, df_cov)\n    Colorbar(fig[1, 2], hm)\n    [text!(ax1, x, y; text=string(df_cov[x, y]), color=:white, fontsize=18, align=(:center, :center)) for x in 1:5, y in 1:5]\n\n    hm2 = heatmap!(ax3, df_cor)\n    Colorbar(fig[1, 4], hm2)\n    [text!(ax3, x, y; text=string(df_cor[x, y]), color=:white, fontsize=18, align=(:center, :center)) for x in 1:5, y in 1:5]\n\n    fig\nend\n\nplot_cov_cor()"
  },
  {
    "objectID": "category/regression/2-ecommerce-linear-reg.html#mlj-workflow",
    "href": "category/regression/2-ecommerce-linear-reg.html#mlj-workflow",
    "title": "2-ecommerce-linear-reg",
    "section": "5. MLJ workflow",
    "text": "5. MLJ workflow\n\n5.1 load model\n\n\nCode\n  LinearRegressor = @load LinearRegressor pkg=MLJLinearModels\n  model=LinearRegressor()\n  mach = MLJ.fit!(machine(model,X,y))\n  fitted_params(mach)\n\n\n[ Info: For silent loading, specify `verbosity=0`. \n[ Info: Training machine(LinearRegressor(fit_intercept = true, …), …).\n┌ Info: Solver: MLJLinearModels.Analytical\n│   iterative: Bool false\n└   max_inner: Int64 200\n\n\nimport MLJLinearModels ✔\n\n\n(coefs = [:x1 =&gt; 25.734271084705085, :x2 =&gt; 38.709153810834366, :x3 =&gt; 0.43673883559434407, :x4 =&gt; 61.57732375487839],\n intercept = -1051.5942553006273,)\n\n\n\n\n5.2 predict\n\n\nCode\n  y_hat =predict(mach, X)\n  \"rmsd\"=&gt;rmsd(y,y_hat)\n\n\n\"rmsd\" =&gt; 9.923256785022247\n\n\n\n\n5.3 plot residuals\n\n\nCode\nresid=y_hat.=y\nstem(resid)"
  },
  {
    "objectID": "category/regression/5-boston-housing-mixture-regression.html",
    "href": "category/regression/5-boston-housing-mixture-regression.html",
    "title": "5-bostonhousing-mixturemodel-regression",
    "section": "",
    "text": "简介\n\n\n\n\n利用 Boston houseing 属性预测房价, 变量可能会存在交互作用\n所以考虑使用混合模型"
  },
  {
    "objectID": "category/regression/5-boston-housing-mixture-regression.html#load-package",
    "href": "category/regression/5-boston-housing-mixture-regression.html#load-package",
    "title": "5-bostonhousing-mixturemodel-regression",
    "section": "1. load package",
    "text": "1. load package\n\n\nCode\nimport MLJ:predict\nusing MLJ"
  },
  {
    "objectID": "category/regression/5-boston-housing-mixture-regression.html#load-data",
    "href": "category/regression/5-boston-housing-mixture-regression.html#load-data",
    "title": "5-bostonhousing-mixturemodel-regression",
    "section": "2. load data",
    "text": "2. load data\n\n\nCode\nX, y= @load_boston;"
  },
  {
    "objectID": "category/regression/5-boston-housing-mixture-regression.html#mlj-workflow",
    "href": "category/regression/5-boston-housing-mixture-regression.html#mlj-workflow",
    "title": "5-bostonhousing-mixturemodel-regression",
    "section": "3. MLJ workflow",
    "text": "3. MLJ workflow\n\n3.1 define model\n\n\nCode\nmodelType= @load GaussianMixtureRegressor pkg = \"BetaML\"\ngmr= modelType()\n\n(fitResults, cache, report) = MLJ.fit(gmr, 1, X, y);\n\n\nimport BetaML ✔\nIter. 1:    Var. of the post  21.74887448784977       Log-likelihood -21687.09917379566\n\n\n[ Info: For silent loading, specify `verbosity=0`. \n\n\n\n\n3.2 results\n\n\nCode\ny_res= predict(gmr, fitResults, X)\nrmse(y_res,y)\n\n\n7.9566567641159605"
  },
  {
    "objectID": "category/regression/1-salary-linear-reg.html",
    "href": "category/regression/1-salary-linear-reg.html",
    "title": "1-salary-linear-reg",
    "section": "",
    "text": "简介\n\n\n\n\nexplore YearsExperience and Salary relationship\n\n\ndataset: kaggle salary dataset\n数据类型需要做转换: to_ScienceType(d)=coerce(d,:YearsExperience=&gt;Continuous,:Salary=&gt;Continuous)\nusing MLJLinearModels.jl 🔗"
  },
  {
    "objectID": "category/regression/1-salary-linear-reg.html#load-package",
    "href": "category/regression/1-salary-linear-reg.html#load-package",
    "title": "1-salary-linear-reg",
    "section": "1. load package",
    "text": "1. load package\n\n\nCode\n    include(\"../utils.jl\")\n    import MLJ:fit!,fitted_params\n    using GLMakie,MLJ,CSV,DataFrames"
  },
  {
    "objectID": "category/regression/1-salary-linear-reg.html#process-data",
    "href": "category/regression/1-salary-linear-reg.html#process-data",
    "title": "1-salary-linear-reg",
    "section": "2. process data",
    "text": "2. process data\n\nload(csv)-&gt;dataframe ==&gt;sciencetype ==&gt;MLJ table\n\n\n\n\nCode\ndf=CSV.File(\"./data/salary_dataset.csv\") |&gt; DataFrame |&gt; dropmissing;\nfirst(df,5)\n\n\n5×3 DataFrame\n\n\n\nRow\nColumn1\nYearsExperience\nSalary\n\n\n\nInt64\nFloat64\nFloat64\n\n\n\n\n1\n0\n1.2\n39344.0\n\n\n2\n1\n1.4\n46206.0\n\n\n3\n2\n1.6\n37732.0\n\n\n4\n3\n2.1\n43526.0\n\n\n5\n4\n2.3\n39892.0\n\n\n\n\n\n\n\n\n\n\nCode\nto_ScienceType(d)=coerce(d,:YearsExperience=&gt;Continuous,:Salary=&gt;Continuous)\nnew_df=to_ScienceType(df)\nfirst(new_df,5)\n\n\n5×3 DataFrame\n\n\n\nRow\nColumn1\nYearsExperience\nSalary\n\n\n\nInt64\nFloat64\nFloat64\n\n\n\n\n1\n0\n1.2\n39344.0\n\n\n2\n1\n1.4\n46206.0\n\n\n3\n2\n1.6\n37732.0\n\n\n4\n3\n2.1\n43526.0\n\n\n5\n4\n2.3\n39892.0\n\n\n\n\n\n\n\n\n\n\nCode\n X=MLJ.table(reshape(new_df[:,2],30,1))\n y=Vector(new_df[:,3])\n show(y)\n\n\n[39344.0, 46206.0, 37732.0, 43526.0, 39892.0, 56643.0, 60151.0, 54446.0, 64446.0, 57190.0, 63219.0, 55795.0, 56958.0, 57082.0, 61112.0, 67939.0, 66030.0, 83089.0, 81364.0, 93941.0, 91739.0, 98274.0, 101303.0, 113813.0, 109432.0, 105583.0, 116970.0, 112636.0, 122392.0, 121873.0]"
  },
  {
    "objectID": "category/regression/1-salary-linear-reg.html#mlj-workflow",
    "href": "category/regression/1-salary-linear-reg.html#mlj-workflow",
    "title": "1-salary-linear-reg",
    "section": "3. MLJ workflow",
    "text": "3. MLJ workflow\n\n3.1 load model\n\n  LinearRegressor = @load LinearRegressor pkg=MLJLinearModels\n  model=LinearRegressor()\n  mach = MLJ.fit!(machine(model,X,y))\n  fp=MLJ.fitted_params(mach)  #学习的模型参数\n\n[ Info: For silent loading, specify `verbosity=0`. \n[ Info: Training machine(LinearRegressor(fit_intercept = true, …), …).\n┌ Info: Solver: MLJLinearModels.Analytical\n│   iterative: Bool false\n└   max_inner: Int64 200\n\n\nimport MLJLinearModels ✔\n\n\n(coefs = [:x1 =&gt; 9449.962321455077],\n intercept = 24848.203966523164,)\n\n\n\n\n3.2 build linear function\n\n\nCode\n    a=fp.coefs[1,1][2]\n    b=fp.intercept\n    line_func(t)=a*t+b\n\n\nline_func (generic function with 1 method)"
  },
  {
    "objectID": "category/regression/1-salary-linear-reg.html#plot-results",
    "href": "category/regression/1-salary-linear-reg.html#plot-results",
    "title": "1-salary-linear-reg",
    "section": "4. plot results",
    "text": "4. plot results\n\n\nCode\nxs=range(extrema(new_df[:,2])...,200)\nfig=Figure()\nax=Axis(fig[1,1];xlabel=\"YearsExperience\",ylabel=\"Salary\")\nlines!(ax,xs,line_func.(xs);label=\"fit-line\",linewidth=3)\nscatter!(ax,new_df[:,2],new_df[:,3];label=\"data\",marker_style...)\naxislegend(ax)\nfig"
  },
  {
    "objectID": "category/regression/7-test-latexify.html",
    "href": "category/regression/7-test-latexify.html",
    "title": "7-latexify-test",
    "section": "",
    "text": "Code\nusing Latexify,Markdown,Symbolics\n\n@variables x\nexpr=latexify(3x^3 + 2x - 5)\n\nMarkdown.parse(\"\"\"$(expr)\"\"\")\n\n\n\\[\\begin{equation} -5 + 2 x + 3 x^{3} \\end{equation}\\]"
  },
  {
    "objectID": "category/regression/6-compare of BetalML method.html",
    "href": "category/regression/6-compare of BetalML method.html",
    "title": "6-compare of BetalML models",
    "section": "",
    "text": "简介\n\n\n\n使用 BetaMLjl 库 on german-creditcard dataset\n\nref :german-creditcard\n类型转换:coerce(d,autotype(d, (:few_to_finite, :discrete_to_continuous)))\nBetaML是julia中另一个大型的机器学习库,参考文档:BetaML Doc"
  },
  {
    "objectID": "category/regression/6-compare of BetalML method.html#load-package",
    "href": "category/regression/6-compare of BetalML method.html#load-package",
    "title": "6-compare of BetalML models",
    "section": "1. load package",
    "text": "1. load package\n\n\nCode\ninclude(\"../utils.jl\")\nimport MLJ:predict,predict_mode\nimport BetaML\nusing DataFrames,MLJ,CSV,MLJModelInterface,GLMakie\nusing CatBoost.MLJCatBoostInterface"
  },
  {
    "objectID": "category/regression/6-compare of BetalML method.html#load-data",
    "href": "category/regression/6-compare of BetalML method.html#load-data",
    "title": "6-compare of BetalML models",
    "section": "2. load data",
    "text": "2. load data\n\n\nCode\n   Xtrain, Xtest, ytrain, ytest,cat= load_german_creditcard();"
  },
  {
    "objectID": "category/regression/6-compare of BetalML method.html#define-models",
    "href": "category/regression/6-compare of BetalML method.html#define-models",
    "title": "6-compare of BetalML models",
    "section": "3. define models",
    "text": "3. define models\n\n\nCode\nfunction define_models()\n\n        modelType1= @load NeuralNetworkClassifier pkg = \"BetaML\"\n\n        layers= [BetaML.DenseLayer(19,8,f=BetaML.relu),BetaML.DenseLayer(8,8,f=BetaML.relu),BetaML.DenseLayer(8,2,f=BetaML.relu),BetaML.VectorFunctionLayer(2,f=BetaML.softmax)];\n        nn_model= modelType1(layers=layers,opt_alg=BetaML.ADAM())\n\n        modelType2= @load DecisionTreeClassifier pkg = \"BetaML\" verbosity=0\n        dt_model= modelType2()\n\n        modelType3= @load KernelPerceptron pkg = \"BetaML\"\n        kp_model= modelType3()\n\n\n        modelType4= @load LinearPerceptron pkg = \"BetaML\"\n        lp_model= modelType4()\n\n        modelType5= @load Pegasos pkg = \"BetaML\" verbosity=0\n        peg_model=modelType5()\n\n\n        modelType6= @load RandomForestClassifier pkg = \"BetaML\" verbosity=0\n        rf_model=modelType6()\n\n        \n        cat_model=CatBoostClassifier(iterations=5)\n\n        models=[nn_model,dt_model,kp_model,lp_model,peg_model,rf_model,cat_model]\n        models_name=[\"nn\",\"dt\",\"kp\",\"lp\",\"peg\",\"rf\",\"cat\"]\n        return models,models_name\n    end\n\n    models,models_name=define_models()\n\n\n[ Info: For silent loading, specify `verbosity=0`. \n[ Info: For silent loading, specify `verbosity=0`. \n[ Info: For silent loading, specify `verbosity=0`. \n\n\nimport BetaML ✔\nimport BetaML ✔\nimport BetaML ✔\n\n\n(Probabilistic[NeuralNetworkClassifier(layers = BetaML.Nn.AbstractLayer[BetaML.Nn.DenseLayer([-0.36074636511061065 -0.39582846276007433 -0.19367369489258768 0.2680078206831555 0.23415797915589948 -0.35426717723464507 0.41873972936820797 0.03695708843884965 -0.1262241154740001 -0.4535341279511609 0.27083756550881694 -0.26285190070170183 -0.29113824789040094 0.3272732026253102 0.3120181348536681 0.03189504313141717 0.17859507646360423 0.24100348772661923 0.014525967665540818; 0.02585857761506677 -0.1786289777618676 0.27390992608661585 -0.00882009262935829 -0.05597939255352807 -0.45185469645137644 0.43448083345893546 -0.07933636613135336 -0.40808183079083227 -0.1512087063152568 -0.22346202440402502 0.24282973121527757 -0.4611082088959598 -0.22314239815908504 -0.2040062087828935 -0.23716874176485098 -0.4007849436405437 -0.029299013620295244 -0.2240163921875015; 0.3586660049153875 0.0990446439566613 -0.30304464083062305 -0.35711866133831294 -0.18581141830140957 0.10300116526719799 -0.3547092905827105 0.17358444569480663 0.46816569231449073 0.36725354636566204 -0.09950624589607898 -0.18348423586113166 -0.05591644911594651 0.21540326133872428 0.4397024519627983 -0.019152022051641848 0.015081037200303848 -0.09338789491179 0.2698572766549305; -0.14737750284903278 0.15390901525950657 0.11733088463889524 -0.18553420478116528 0.2773342867980156 -0.44187683747564216 -0.07128222618035901 -0.3975783832585831 -0.1797548030782582 0.45414987217334984 0.11774352278251005 0.4318637917472961 0.34114366748895236 0.20543094312431615 0.45879918119036506 0.19966031284458824 -0.4243977564030008 0.3528498049246546 -0.26449251745539387; -0.46603077560973166 0.363177679644008 0.15387610207235164 0.16878070443105436 0.22469025601685005 0.43163009427259763 0.3433671636225248 -0.04331120409999056 -0.3450286254110857 0.27013134708859105 -0.1246971621378602 0.18019183676577127 -0.22935636935801848 -0.38713683379338093 -0.36324994527472265 0.12175941762041481 0.37182252248090214 -0.2946228229043437 0.36728385779700773; -0.35965444222821236 -0.2513459765142385 -0.12760789988466997 -0.3651832232912821 0.2275393345538726 0.19344000211089812 -0.06541914124742532 0.45592078923421525 -0.3588317610866417 0.37053197119661924 -0.16897336019104503 0.006708286081282766 0.22294499850839905 0.3064633029426777 0.449684771230571 0.29878199021450175 -0.19723891228337898 0.03398494223628351 0.195930874969185; 0.16768892675786945 0.20178877728541117 -0.01920955698773008 -0.07346464258077734 -0.22641700608346715 -0.3972909747656714 -0.3926505747242142 -0.3211783657517294 -0.42299054770886885 0.4394603691078505 -0.020340987431912816 0.31152821754851673 0.275435690977708 -0.453777188734648 0.38653852340376965 0.2257564654780106 -0.39273527136599073 -0.3588904629697215 0.04673991700334451; -0.3922339208951156 0.4104731956148045 0.01849632586826505 -0.2311936494942672 0.05614872575245905 -0.10645646149582344 -0.4578158813458524 0.17582732885781888 0.007762622179870338 0.1398437234045315 -0.2026471964256374 0.3674505083332545 -0.26909992476264555 -0.20785693976235886 0.07734529876859592 0.08917618938717092 -0.22274107976966068 -0.3823399200961872 -0.45505603896994484], [-0.157465439622054, -0.21995520319116818, -0.3384789069755978, -0.15006788522938158, -0.08068739583553858, 0.17488394613124297, -0.04748199633913597, -0.3250052328690887], BetaML.Utils.relu, BetaML.Utils.drelu), BetaML.Nn.DenseLayer([-0.3852959591608028 -0.553059892716297 -0.015028124586988656 -0.011201024404014936 0.005100673463055649 -0.18746389838773353 -0.4465071177773833 -0.24705649867006285; 0.6026146990300689 -0.33870198929549894 0.2718518742522277 -0.3384705743525871 -0.06814271449805787 0.606002135337379 -0.10336455886078566 0.26238572386113823; 0.45018281052830456 0.18679055621241314 -0.37362480422350963 0.006078042783034587 -0.45064052026604706 -0.1425599823506864 -0.3585911486603981 -0.6063601118282695; -0.05738177001216915 -0.3564277181599287 -0.36781688568508414 -0.14252074674595333 0.2571075127666419 0.19183099681926707 -0.018662422915370347 -0.3510293358769623; -0.08061251239900558 0.1179048173797197 -0.25520661838834113 -0.02273079835591796 0.38222026437329126 0.40094107662179646 -0.5807559333068457 0.36662125095206255; 0.33297001370651136 0.33740265915614154 0.11892808620953843 -0.461833943645412 -0.44731582380216783 -0.1810395086037453 0.2447640455667498 0.18200413571170693; -0.48967054357747297 -0.4865518207276439 -0.24790297957249452 -0.45395785625464546 -0.21218635943332892 -0.11260342698590892 -0.38292860160231035 -0.5607840330610061; 0.49172091443161037 0.348025736136519 0.04600440542299833 -0.5245141418067015 -0.16209562928447985 -0.16401386904196824 -0.08199421251258743 0.043141435301436104], [0.5320229402035459, 0.08848618862963409, 0.49077131013907294, 0.40163369167512397, -0.3241193921715959, -0.4400009135782846, 0.07456092888227783, 0.36052644514730536], BetaML.Utils.relu, BetaML.Utils.drelu), BetaML.Nn.DenseLayer([-0.3367271772548713 0.6877326959270641 0.1575891073545942 -0.4441500273567661 0.20426279244526513 -0.08785955388176736 0.09549279041837222 -0.25434472335021696; -0.21366575215568595 0.01925661356946584 0.654401524198115 0.07698019071966455 0.006405545613967667 -0.4771138208850888 -0.7483462850040817 0.09549653596307062], [-0.604516114936473, -0.11748999487867229], BetaML.Utils.relu, BetaML.Utils.drelu), BetaML.Nn.VectorFunctionLayer{0}(fill(NaN), 2, 2, BetaML.Utils.softmax, BetaML.Utils.dsoftmax, nothing)], …), DecisionTreeClassifier(max_depth = 0, …), KernelPerceptron(kernel = radial_kernel, …), LinearPerceptron(initial_coefficients = nothing, …), Pegasos(initial_coefficients = nothing, …), RandomForestClassifier(n_trees = 30, …), CatBoostClassifier(iterations = 5, …)], [\"nn\", \"dt\", \"kp\", \"lp\", \"peg\", \"rf\", \"cat\"])"
  },
  {
    "objectID": "category/regression/6-compare of BetalML method.html#train-model",
    "href": "category/regression/6-compare of BetalML method.html#train-model",
    "title": "6-compare of BetalML models",
    "section": "4. train model",
    "text": "4. train model\n\n\nCode\nfunction train_model()\n    for (idx,model) in enumerate(models[1:6])\n        local (fitResults, cache, report) = MLJ.fit(model, 0, Xtrain,ytrain);\n        local est_classes= predict_mode(model, fitResults, Xtest)\n        local acc=accuracy(ytest,est_classes)|&gt;d-&gt;round(d, digits=3)\n        @info \"$(models_name[idx])===&gt;$(acc)\"\n    end\nend\n\ntrain_model()\n\n\n[ Info: nn===&gt;0.305\n[ Info: dt===&gt;0.705\n[ Info: kp===&gt;0.335\n[ Info: lp===&gt;0.45\n[ Info: peg===&gt;0.695\n[ Info: rf===&gt;0.735"
  },
  {
    "objectID": "category/regression/8-iris-logistics-reg.html",
    "href": "category/regression/8-iris-logistics-reg.html",
    "title": "8-iris-logistics-reg",
    "section": "",
    "text": "简介\n\n\n\n\nref: probml page84 figure 2.13\ndataset:iris\nplots:使用 GLMakie:contourf 方法"
  },
  {
    "objectID": "category/regression/8-iris-logistics-reg.html#load-package",
    "href": "category/regression/8-iris-logistics-reg.html#load-package",
    "title": "8-iris-logistics-reg",
    "section": "1. load package",
    "text": "1. load package\n\n\nCode\n    include(\"../utils.jl\")\n    import MLJ:fit!,fitted_params\n    using GLMakie,MLJ,CSV,DataFrames"
  },
  {
    "objectID": "category/regression/8-iris-logistics-reg.html#process-data",
    "href": "category/regression/8-iris-logistics-reg.html#process-data",
    "title": "8-iris-logistics-reg",
    "section": "2 process data",
    "text": "2 process data\n\n2.1 import iris datset\n\n\nCode\niris = load_iris();\n\n#selectrows(iris, 1:3)  |&gt; pretty\n\niris = DataFrames.DataFrame(iris);\nfirst(iris,5)|&gt;display\ny, X = unpack(iris, ==(:target); rng=123);\n\nX=select!(X,3:4)\n\nbyCat = iris.target\ncateg = unique(byCat)\ncolors1 = [:orange,:lightgreen,:purple];\n\n\n5×5 DataFrame\n\n\n\nRow\nsepal_length\nsepal_width\npetal_length\npetal_width\ntarget\n\n\n\nFloat64\nFloat64\nFloat64\nFloat64\nCat…\n\n\n\n\n1\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n2\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n3\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n4\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n5\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n\n\n\n\n\n\n2.2 make desc boundary data\n\n生成决策边界实际是利用训练模型对区间内的每个点都做出预测,利用两个属性的最大值和最小值 生成 grid 数据,这是 test数据\n\n\n\nCode\n# grid data\n   n1 = n2 = 200\n   tx = LinRange(0, 8, 200)\n   ty = LinRange(-1, 4, 200)\n   X_test = mapreduce(collect, hcat, Iterators.product(tx, ty))\n   X_test = MLJ.table(X_test')\n\n\nTables.MatrixTable{LinearAlgebra.Adjoint{Float64, Matrix{Float64}}} with 40000 rows, 2 columns, and schema:\n :x1  Float64\n :x2  Float64"
  },
  {
    "objectID": "category/regression/8-iris-logistics-reg.html#logisitcs-model",
    "href": "category/regression/8-iris-logistics-reg.html#logisitcs-model",
    "title": "8-iris-logistics-reg",
    "section": "3. Logisitcs model",
    "text": "3. Logisitcs model\n\n3.1 training model\n\n\nCode\n     LogisticClassifier = @load LogisticClassifier pkg=MLJLinearModels\n      \n     model = machine(LogisticClassifier(), X,y )\n     fit!(model)\n\n\nimport MLJLinearModels ✔\n\n\n[ Info: For silent loading, specify `verbosity=0`. \n[ Info: Training machine(LogisticClassifier(lambda = 2.220446049250313e-16, …), …).\n┌ Info: Solver: MLJLinearModels.LBFGS{Optim.Options{Float64, Nothing}, NamedTuple{(), Tuple{}}}\n│   optim_options: Optim.Options{Float64, Nothing}\n└   lbfgs_options: NamedTuple{(), Tuple{}} NamedTuple()\n\n\ntrained Machine; caches model-specific representations of data\n  model: LogisticClassifier(lambda = 2.220446049250313e-16, …)\n  args: \n    1:  Source @794 ⏎ Table{AbstractVector{Continuous}}\n    2:  Source @579 ⏎ AbstractVector{Multiclass{3}}\n\n\n\n\n3.2 predict\n\n\nCode\nŷ = MLJ.predict(model, X_test)\n\nres=mode.(ŷ)|&gt;d-&gt;reshape(d,200,200)\nfunction trans(i)\n     \n    if i==\"setosa\"\n       res=1\n    elseif  i==\"versicolor\"\n       res=2\n       \n    else\n       res=3\n    end\nend\nypred=[trans(res[i,j]) for i in 1:200, j in 1:200]\n\n\n200×200 Matrix{Int64}:\n 1  1  1  1  1  1  1  1  1  1  1  1  1  …  2  2  2  2  2  2  2  2  2  2  2  2\n 1  1  1  1  1  1  1  1  1  1  1  1  1     2  2  2  2  2  2  2  2  2  2  2  2\n 1  1  1  1  1  1  1  1  1  1  1  1  1     2  2  2  2  2  2  2  2  2  2  2  2\n 1  1  1  1  1  1  1  1  1  1  1  1  1     2  2  2  2  2  2  2  2  2  2  2  2\n 1  1  1  1  1  1  1  1  1  1  1  1  1     2  2  2  2  2  2  2  2  2  2  2  2\n 1  1  1  1  1  1  1  1  1  1  1  1  1  …  2  2  2  2  2  2  2  2  2  2  2  2\n 1  1  1  1  1  1  1  1  1  1  1  1  1     2  2  2  2  2  2  2  2  2  2  2  2\n 1  1  1  1  1  1  1  1  1  1  1  1  1     2  2  2  2  2  2  2  2  2  2  2  2\n 1  1  1  1  1  1  1  1  1  1  1  1  1     2  2  2  2  2  2  2  2  2  2  2  2\n 1  1  1  1  1  1  1  1  1  1  1  1  1     2  2  2  2  2  2  2  2  2  2  2  2\n 1  1  1  1  1  1  1  1  1  1  1  1  1  …  2  2  2  2  2  2  2  2  2  2  2  2\n 1  1  1  1  1  1  1  1  1  1  1  1  1     2  2  2  2  2  2  2  2  2  2  2  2\n 1  1  1  1  1  1  1  1  1  1  1  1  1     2  2  2  2  2  2  2  2  2  2  2  2\n ⋮              ⋮              ⋮        ⋱        ⋮              ⋮           \n 2  2  2  2  2  2  2  2  2  2  2  2  2     3  3  3  3  3  3  3  3  3  3  3  3\n 2  2  2  2  2  2  2  2  2  2  2  2  2     3  3  3  3  3  3  3  3  3  3  3  3\n 2  2  2  2  2  2  2  2  2  2  2  2  2  …  3  3  3  3  3  3  3  3  3  3  3  3\n 2  2  2  2  2  2  2  2  2  2  2  2  2     3  3  3  3  3  3  3  3  3  3  3  3\n 2  2  2  2  2  2  2  2  2  2  2  2  2     3  3  3  3  3  3  3  3  3  3  3  3\n 2  2  2  2  2  2  2  2  2  2  2  2  2     3  3  3  3  3  3  3  3  3  3  3  3\n 2  2  2  2  2  2  2  2  2  2  2  2  2     3  3  3  3  3  3  3  3  3  3  3  3\n 2  2  2  2  2  2  2  2  2  2  2  2  2  …  3  3  3  3  3  3  3  3  3  3  3  3\n 2  2  2  2  2  2  2  2  2  2  2  2  2     3  3  3  3  3  3  3  3  3  3  3  3\n 2  2  2  2  2  2  2  2  2  2  2  2  2     3  3  3  3  3  3  3  3  3  3  3  3\n 2  2  2  2  2  2  2  2  2  2  2  2  2     3  3  3  3  3  3  3  3  3  3  3  3\n 2  2  2  2  2  2  2  2  2  2  2  2  2     3  3  3  3  3  3  3  3  3  3  3  3"
  },
  {
    "objectID": "category/regression/8-iris-logistics-reg.html#plot-res",
    "href": "category/regression/8-iris-logistics-reg.html#plot-res",
    "title": "8-iris-logistics-reg",
    "section": "4 plot res",
    "text": "4 plot res\n\n\nCode\n   function  add_legend(axs)\n      Legend(fig[1,2], axs,\"Label\";width=100,height=200)\n   end\n\n   function desision_boundary(ax)\n      axs=[]\n      for (k, c) in enumerate(categ)\n         indc = findall(x -&gt; x == c, byCat)\n         #@show indc\n         x=scatter!(iris[:,3][indc],iris[:,4][indc];color=colors1[k],markersize=14)\n         push!(axs,x)\n      end\n      return axs\n   end\n\n   fig = Figure(resolution=(800,600))\n   ax=Axis(fig[1,1],xlabel=\"Petal length\",ylabel=\"Petal width\",title=L\"Iris Logistics classfication\")\n   contourf!(ax,tx, ty, ypred, levels=length(categ))\n   axs=desision_boundary(ax)\n   Legend(fig[1,2],[axs...],categ)\n   fig"
  },
  {
    "objectID": "category/regression/4-german-creditcard-logistics-reg.html",
    "href": "category/regression/4-german-creditcard-logistics-reg.html",
    "title": "4-german-creditcard-logistics-reg",
    "section": "",
    "text": "简介\n\n\n\n\nref :german-creditcard\nscitype 转换 参考:autotype(d, :few_to_finite)方法"
  },
  {
    "objectID": "category/regression/4-german-creditcard-logistics-reg.html#load-package",
    "href": "category/regression/4-german-creditcard-logistics-reg.html#load-package",
    "title": "4-german-creditcard-logistics-reg",
    "section": "1. load package",
    "text": "1. load package\n\n\nCode\ninclude(\"../utils.jl\")\nimport MLJ:predict,fit!,predict_mode,range\nusing DataFrames,MLJ,CSV,MLJModelInterface,GLMakie"
  },
  {
    "objectID": "category/regression/4-german-creditcard-logistics-reg.html#data-procsssing",
    "href": "category/regression/4-german-creditcard-logistics-reg.html#data-procsssing",
    "title": "4-german-creditcard-logistics-reg",
    "section": "2. data procsssing",
    "text": "2. data procsssing\n\n\nCode\nXtrain, Xtest, ytrain, ytest,cat= load_german_creditcard();"
  },
  {
    "objectID": "category/regression/4-german-creditcard-logistics-reg.html#mlj-workflow",
    "href": "category/regression/4-german-creditcard-logistics-reg.html#mlj-workflow",
    "title": "4-german-creditcard-logistics-reg",
    "section": "3. MLJ workflow",
    "text": "3. MLJ workflow\n\n3.1 define model\n\n\nCode\nLogisticClassifier = @load LogisticClassifier pkg=MLJLinearModels\nmodel=LogisticClassifier()\nNuSVC = @load NuSVC pkg=LIBSVM\nmodel2 = NuSVC()\nKNNClassifier = @load KNNClassifier pkg=NearestNeighborModels\nmodel3 = KNNClassifier(weights = NearestNeighborModels.Inverse())\n\n\"定义 几个 tune 参数的区间 \"\nk1 =range(model, :gamma, lower=0.1, upper=1.2);\nk2 =range(model, :lambda, lower=0.1, upper=1.2);\nk3 =range(model, :penalty, values=([:l2, :l1,:en,:none]));\nk4 =range(model, :fit_intercept, values=([true, false]));\n\ntuning_logistic = TunedModel(model=model,\n                             resampling = CV(nfolds=4, rng=1234),\n                             tuning = Grid(resolution=8),\n                             range = [k1,k2],\n                             measure=accuracy)\nmach = machine(tuning_logistic, Xtrain, ytrain;scitype_check_level=0)|&gt;fit!\n\n\n[ Info: For silent loading, specify `verbosity=0`. \n[ Info: For silent loading, specify `verbosity=0`. \n[ Info: For silent loading, specify `verbosity=0`. \n[ Info: Training machine(ProbabilisticTunedModel(model = LogisticClassifier(lambda = 2.220446049250313e-16, …), …), …).\n[ Info: Attempting to evaluate 64 models.\nEvaluating over 64 metamodels:   0%[&gt;                        ]  ETA: N/A┌ Warning: The number and/or types of data arguments do not match what the specified model\n│ supports. Suppress this type check by specifying `scitype_check_level=0`.\n│ \n│ Run `@doc MLJLinearModels.LogisticClassifier` to learn more about your model's requirements.\n│ \n│ Commonly, but non exclusively, supervised models are constructed using the syntax\n│ `machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n│ constructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n│ sample or class weights.\n│ \n│ In general, data in `machine(model, data...)` is expected to satisfy\n│ \n│     scitype(data) &lt;: MLJ.fit_data_scitype(model)\n│ \n│ In the present case:\n│ \n│ scitype(data) = Tuple{Table{Union{AbstractVector{Continuous}, AbstractVector{OrderedFactor{33}}, AbstractVector{OrderedFactor{10}}, AbstractVector{OrderedFactor{5}}, AbstractVector{OrderedFactor{53}}, AbstractVector{OrderedFactor{3}}, AbstractVector{OrderedFactor{4}}, AbstractVector{OrderedFactor{2}}}}, AbstractVector{OrderedFactor{2}}}\n│ \n│ fit_data_scitype(model) = Tuple{Table{&lt;:AbstractVector{&lt;:Continuous}}, AbstractVector{&lt;:Finite}}\n└ @ MLJBase ~/.julia/packages/MLJBase/fEiP2/src/machines.jl:230\nEvaluating over 64 metamodels:   2%[&gt;                        ]  ETA: 0:13:55Evaluating over 64 metamodels:   3%[&gt;                        ]  ETA: 0:07:07Evaluating over 64 metamodels:   5%[=&gt;                       ]  ETA: 0:04:40Evaluating over 64 metamodels:   6%[=&gt;                       ]  ETA: 0:03:27Evaluating over 64 metamodels:   8%[=&gt;                       ]  ETA: 0:02:43Evaluating over 64 metamodels:   9%[==&gt;                      ]  ETA: 0:02:13Evaluating over 64 metamodels:  11%[==&gt;                      ]  ETA: 0:01:52Evaluating over 64 metamodels:  12%[===&gt;                     ]  ETA: 0:01:37Evaluating over 64 metamodels:  14%[===&gt;                     ]  ETA: 0:01:25Evaluating over 64 metamodels:  16%[===&gt;                     ]  ETA: 0:01:15Evaluating over 64 metamodels:  17%[====&gt;                    ]  ETA: 0:01:07Evaluating over 64 metamodels:  19%[====&gt;                    ]  ETA: 0:01:00Evaluating over 64 metamodels:  20%[=====&gt;                   ]  ETA: 0:00:54Evaluating over 64 metamodels:  22%[=====&gt;                   ]  ETA: 0:00:50Evaluating over 64 metamodels:  23%[=====&gt;                   ]  ETA: 0:00:45Evaluating over 64 metamodels:  25%[======&gt;                  ]  ETA: 0:00:42Evaluating over 64 metamodels:  27%[======&gt;                  ]  ETA: 0:00:38Evaluating over 64 metamodels:  28%[=======&gt;                 ]  ETA: 0:00:36Evaluating over 64 metamodels:  30%[=======&gt;                 ]  ETA: 0:00:33Evaluating over 64 metamodels:  31%[=======&gt;                 ]  ETA: 0:00:31Evaluating over 64 metamodels:  33%[========&gt;                ]  ETA: 0:00:29Evaluating over 64 metamodels:  34%[========&gt;                ]  ETA: 0:00:27Evaluating over 64 metamodels:  36%[========&gt;                ]  ETA: 0:00:25Evaluating over 64 metamodels:  38%[=========&gt;               ]  ETA: 0:00:23Evaluating over 64 metamodels:  39%[=========&gt;               ]  ETA: 0:00:22Evaluating over 64 metamodels:  41%[==========&gt;              ]  ETA: 0:00:20Evaluating over 64 metamodels:  42%[==========&gt;              ]  ETA: 0:00:19Evaluating over 64 metamodels:  44%[==========&gt;              ]  ETA: 0:00:18Evaluating over 64 metamodels:  45%[===========&gt;             ]  ETA: 0:00:17Evaluating over 64 metamodels:  47%[===========&gt;             ]  ETA: 0:00:16Evaluating over 64 metamodels:  48%[============&gt;            ]  ETA: 0:00:15Evaluating over 64 metamodels:  50%[============&gt;            ]  ETA: 0:00:14Evaluating over 64 metamodels:  52%[============&gt;            ]  ETA: 0:00:13Evaluating over 64 metamodels:  53%[=============&gt;           ]  ETA: 0:00:12Evaluating over 64 metamodels:  55%[=============&gt;           ]  ETA: 0:00:12Evaluating over 64 metamodels:  56%[==============&gt;          ]  ETA: 0:00:11Evaluating over 64 metamodels:  58%[==============&gt;          ]  ETA: 0:00:10Evaluating over 64 metamodels:  59%[==============&gt;          ]  ETA: 0:00:10Evaluating over 64 metamodels:  61%[===============&gt;         ]  ETA: 0:00:09Evaluating over 64 metamodels:  62%[===============&gt;         ]  ETA: 0:00:08Evaluating over 64 metamodels:  64%[================&gt;        ]  ETA: 0:00:08Evaluating over 64 metamodels:  66%[================&gt;        ]  ETA: 0:00:07Evaluating over 64 metamodels:  67%[================&gt;        ]  ETA: 0:00:07Evaluating over 64 metamodels:  69%[=================&gt;       ]  ETA: 0:00:06Evaluating over 64 metamodels:  70%[=================&gt;       ]  ETA: 0:00:06Evaluating over 64 metamodels:  72%[=================&gt;       ]  ETA: 0:00:06Evaluating over 64 metamodels:  73%[==================&gt;      ]  ETA: 0:00:05Evaluating over 64 metamodels:  75%[==================&gt;      ]  ETA: 0:00:05Evaluating over 64 metamodels:  77%[===================&gt;     ]  ETA: 0:00:04Evaluating over 64 metamodels:  78%[===================&gt;     ]  ETA: 0:00:04Evaluating over 64 metamodels:  80%[===================&gt;     ]  ETA: 0:00:04Evaluating over 64 metamodels:  81%[====================&gt;    ]  ETA: 0:00:03Evaluating over 64 metamodels:  83%[====================&gt;    ]  ETA: 0:00:03Evaluating over 64 metamodels:  84%[=====================&gt;   ]  ETA: 0:00:03Evaluating over 64 metamodels:  86%[=====================&gt;   ]  ETA: 0:00:02Evaluating over 64 metamodels:  88%[=====================&gt;   ]  ETA: 0:00:02Evaluating over 64 metamodels:  89%[======================&gt;  ]  ETA: 0:00:02Evaluating over 64 metamodels:  91%[======================&gt;  ]  ETA: 0:00:01Evaluating over 64 metamodels:  92%[=======================&gt; ]  ETA: 0:00:01Evaluating over 64 metamodels:  94%[=======================&gt; ]  ETA: 0:00:01Evaluating over 64 metamodels:  95%[=======================&gt; ]  ETA: 0:00:01Evaluating over 64 metamodels:  97%[========================&gt;]  ETA: 0:00:00Evaluating over 64 metamodels:  98%[========================&gt;]  ETA: 0:00:00Evaluating over 64 metamodels: 100%[=========================] Time: 0:00:14\n┌ Warning: The number and/or types of data arguments do not match what the specified model\n│ supports. Suppress this type check by specifying `scitype_check_level=0`.\n│ \n│ Run `@doc MLJLinearModels.LogisticClassifier` to learn more about your model's requirements.\n│ \n│ Commonly, but non exclusively, supervised models are constructed using the syntax\n│ `machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n│ constructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n│ sample or class weights.\n│ \n│ In general, data in `machine(model, data...)` is expected to satisfy\n│ \n│     scitype(data) &lt;: MLJ.fit_data_scitype(model)\n│ \n│ In the present case:\n│ \n│ scitype(data) = Tuple{Table{Union{AbstractVector{Continuous}, AbstractVector{OrderedFactor{33}}, AbstractVector{OrderedFactor{10}}, AbstractVector{OrderedFactor{5}}, AbstractVector{OrderedFactor{53}}, AbstractVector{OrderedFactor{3}}, AbstractVector{OrderedFactor{4}}, AbstractVector{OrderedFactor{2}}}}, AbstractVector{OrderedFactor{2}}}\n│ \n│ fit_data_scitype(model) = Tuple{Table{&lt;:AbstractVector{&lt;:Continuous}}, AbstractVector{&lt;:Finite}}\n└ @ MLJBase ~/.julia/packages/MLJBase/fEiP2/src/machines.jl:230\n\n\nimport MLJLinearModels ✔\nimport MLJLIBSVMInterface ✔\nimport NearestNeighborModels ✔\n\n\ntrained Machine; does not cache data\n  model: ProbabilisticTunedModel(model = LogisticClassifier(lambda = 2.220446049250313e-16, …), …)\n  args: \n    1:  Source @007 ⏎ Table{Union{AbstractVector{Continuous}, AbstractVector{OrderedFactor{33}}, AbstractVector{OrderedFactor{10}}, AbstractVector{OrderedFactor{5}}, AbstractVector{OrderedFactor{53}}, AbstractVector{OrderedFactor{3}}, AbstractVector{OrderedFactor{4}}, AbstractVector{OrderedFactor{2}}}}\n    2:  Source @757 ⏎ AbstractVector{OrderedFactor{2}}\n\n\n\n\n3.2 predict test results\n\n\nCode\nyhat=predict_mode(mach, Xtest)|&gt;Array\n@info \"german-creditcard 违约预测准确率\"=&gt;accuracy(ytest,yhat)|&gt;d-&gt;round(d,digits=3)\n\n\n[ Info: \"german-creditcard 违约预测准确率\" =&gt; 0.74"
  },
  {
    "objectID": "category/getting-started.html",
    "href": "category/getting-started.html",
    "title": "getting started with MLJ",
    "section": "",
    "text": "import MLJ:evaluate\n    using MLJ,DataFrames\n    iris=load_iris()|&gt;DataFrame\n    display(first(iris,10))\n\n10×5 DataFrame\n\n\n\nRow\nsepal_length\nsepal_width\npetal_length\npetal_width\ntarget\n\n\n\nFloat64\nFloat64\nFloat64\nFloat64\nCat…\n\n\n\n\n1\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n2\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n3\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n4\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n5\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n6\n5.4\n3.9\n1.7\n0.4\nsetosa\n\n\n7\n4.6\n3.4\n1.4\n0.3\nsetosa\n\n\n8\n5.0\n3.4\n1.5\n0.2\nsetosa\n\n\n9\n4.4\n2.9\n1.4\n0.2\nsetosa\n\n\n10\n4.9\n3.1\n1.5\n0.1\nsetosa"
  },
  {
    "objectID": "category/getting-started.html#loading-package-and-data",
    "href": "category/getting-started.html#loading-package-and-data",
    "title": "getting started with MLJ",
    "section": "",
    "text": "import MLJ:evaluate\n    using MLJ,DataFrames\n    iris=load_iris()|&gt;DataFrame\n    display(first(iris,10))\n\n10×5 DataFrame\n\n\n\nRow\nsepal_length\nsepal_width\npetal_length\npetal_width\ntarget\n\n\n\nFloat64\nFloat64\nFloat64\nFloat64\nCat…\n\n\n\n\n1\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n2\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n3\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n4\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n5\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n6\n5.4\n3.9\n1.7\n0.4\nsetosa\n\n\n7\n4.6\n3.4\n1.4\n0.3\nsetosa\n\n\n8\n5.0\n3.4\n1.5\n0.2\nsetosa\n\n\n9\n4.4\n2.9\n1.4\n0.2\nsetosa\n\n\n10\n4.9\n3.1\n1.5\n0.1\nsetosa"
  },
  {
    "objectID": "category/getting-started.html#build-decisiontree-model",
    "href": "category/getting-started.html#build-decisiontree-model",
    "title": "getting started with MLJ",
    "section": "2. build DecisionTree model",
    "text": "2. build DecisionTree model\n\n    y, X = unpack(iris, ==(:target); rng=123);\n    Tree = @load DecisionTreeClassifier pkg=DecisionTree\n    tree = Tree()\n    evaluate(tree, X, y, resampling=CV(shuffle=true),\n                 measures=[log_loss, accuracy],\n                 verbosity=0)\n\n[ Info: For silent loading, specify `verbosity=0`. \n\n\nimport MLJDecisionTreeInterface ✔\n\n\n\nPerformanceEvaluation object with these fields:\n  model, measure, operation, measurement, per_fold,\n  per_observation, fitted_params_per_fold,\n  report_per_fold, train_test_rows, resampling, repeats\nExtract:\n┌──────────────────────┬──────────────┬─────────────┬─────────┬─────────────────\n│ measure              │ operation    │ measurement │ 1.96*SE │ per_fold       ⋯\n├──────────────────────┼──────────────┼─────────────┼─────────┼─────────────────\n│ LogLoss(             │ predict      │ 3.12        │ 1.48    │ [2.88, 1.44, 5 ⋯\n│   tol = 2.22045e-16) │              │             │         │                ⋯\n│ Accuracy()           │ predict_mode │ 0.913       │ 0.041   │ [0.92, 0.96, 0 ⋯\n└──────────────────────┴──────────────┴─────────────┴─────────┴─────────────────\n                                                                1 column omitted"
  },
  {
    "objectID": "category/classification/1-catboost-claffification.html",
    "href": "category/classification/1-catboost-claffification.html",
    "title": "1-catboost-classfication",
    "section": "",
    "text": "dataset\n\n\n\ndataset 参见 clustering-exercises dataset"
  },
  {
    "objectID": "category/classification/1-catboost-claffification.html#load-package",
    "href": "category/classification/1-catboost-claffification.html#load-package",
    "title": "1-catboost-classfication",
    "section": "1. load package",
    "text": "1. load package\n\n\nCode\ninclude(\"../utils.jl\")\nimport Plots:scatter!,contourf\nimport MLJ:predict,predict_mode,measures\nusing Plots, MLJ, CSV, DataFrames\nusing CatBoost.MLJCatBoostInterface"
  },
  {
    "objectID": "category/classification/1-catboost-claffification.html#load-data",
    "href": "category/classification/1-catboost-claffification.html#load-data",
    "title": "1-catboost-classfication",
    "section": "2. load data",
    "text": "2. load data\n\n\nCode\n  df=load_csv(\"basic1\")\n  cat=df[:,:color]|&gt;levels|&gt;length # 类别\n  ytrain, Xtrain =  unpack(df, ==(:color), rng=123);\n  first(df,10)\n\n\n10×3 DataFrame\n\n\n\nRow\nx\ny\ncolor\n\n\n\nFloat64\nFloat64\nInt64\n\n\n\n\n1\n79.4083\n152.834\n0\n\n\n2\n98.0463\n186.911\n0\n\n\n3\n240.579\n48.4737\n1\n\n\n4\n109.687\n277.946\n0\n\n\n5\n249.626\n229.753\n1\n\n\n6\n100.785\n281.983\n0\n\n\n7\n235.33\n109.54\n1\n\n\n8\n262.352\n64.5746\n1\n\n\n9\n76.5589\n204.296\n0\n\n\n10\n245.558\n134.502\n1"
  },
  {
    "objectID": "category/classification/1-catboost-claffification.html#mlj-workflow",
    "href": "category/classification/1-catboost-claffification.html#mlj-workflow",
    "title": "1-catboost-classfication",
    "section": "3. MLJ workflow",
    "text": "3. MLJ workflow\n\n3.1 fitting model\n\n\nCode\n    catboost = CatBoostClassifier(iterations=2,learning_rate=0.20)\n    mach = machine(catboost, Xtrain, ytrain;scitype_check_level=0)|&gt;fit!\n    tx,ty,xtest=boundary_data(df)  # boudary data and xtest \n    ytest = predict_mode(mach, xtest)[:,1]|&gt;Array\n\n\n[ Info: Training machine(CatBoostClassifier(iterations = 2, …), …).\n\n\n40000-element Vector{Int64}:\n 0\n 0\n 0\n 0\n 0\n 0\n 0\n 0\n 0\n 0\n 0\n 0\n 0\n ⋮\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n\n\n\n\n3.2 plot results\n\n\nCode\ncontourf(tx,ty,ytest,levels=cat,color=cgrad(:redsblues),alpha=0.7)\np1=scatter!(df[:,:x],df[:,:y],group=df[:,:color],label=false,ms=3,alpha=0.3)"
  },
  {
    "objectID": "category/classification/2-diabetes-svm-classficiation.html",
    "href": "category/classification/2-diabetes-svm-classficiation.html",
    "title": "2-svm-diabetes-classfication",
    "section": "",
    "text": "介绍\n\n\n\n\n参考博客文章:diagnose-diabetes-with-svm\nSVM(支持向量机)通过引入 kernelfunction,使得模型的分类灵活性大大增强,可以解决更多问题.在julia中可以通过在LIBSVM.jl 引入 kernel function 实现, 参见 文档: Support Vector Machine\nMLJ.jl 通过包装接口也提供相似功能\n响应变量需要转换类型 to_ScienceType(d)=coerce(d,:Outcome=&gt; Multiclass)"
  },
  {
    "objectID": "category/classification/2-diabetes-svm-classficiation.html#load-package",
    "href": "category/classification/2-diabetes-svm-classficiation.html#load-package",
    "title": "2-svm-diabetes-classfication",
    "section": "1. load package",
    "text": "1. load package\n\n\nCode\ninclude(\"../utils.jl\")\nimport MLJ: fit!, predict\nusing CSV,DataFrames,Random\nusing MLJ\nusing Plots\nusing KernelFunctions"
  },
  {
    "objectID": "category/classification/2-diabetes-svm-classficiation.html#process-data",
    "href": "category/classification/2-diabetes-svm-classficiation.html#process-data",
    "title": "2-svm-diabetes-classfication",
    "section": "2. process data",
    "text": "2. process data\n\n\nCode\n df=load_csv(\"diabetes\")\n to_ScienceType(d)=coerce(d,:Outcome=&gt; Multiclass)\n df=to_ScienceType(df)\n first(df,5)|&gt;display\n y, X =  unpack(df, ==(:Outcome), rng=123);\n (Xtrain, Xtest), (ytrain, ytest)  = partition((X, y), 0.7, multi=true,  rng=123)\ndisplay(schema(X))\n\n\n5×9 DataFrame\n\n\n\nRow\nPregnancies\nGlucose\nBloodPressure\nSkinThickness\nInsulin\nBMI\nDiabetesPedigreeFunction\nAge\nOutcome\n\n\n\nInt64\nInt64\nInt64\nInt64\nInt64\nFloat64\nFloat64\nInt64\nCat…\n\n\n\n\n1\n6\n148\n72\n35\n0\n33.6\n0.627\n50\n1\n\n\n2\n1\n85\n66\n29\n0\n26.6\n0.351\n31\n0\n\n\n3\n8\n183\n64\n0\n0\n23.3\n0.672\n32\n1\n\n\n4\n1\n89\n66\n23\n94\n28.1\n0.167\n21\n0\n\n\n5\n0\n137\n40\n35\n168\n43.1\n2.288\n33\n1\n\n\n\n\n\n\n\n┌──────────────────────────┬────────────┬─────────┐\n│ names                    │ scitypes   │ types   │\n├──────────────────────────┼────────────┼─────────┤\n│ Pregnancies              │ Count      │ Int64   │\n│ Glucose                  │ Count      │ Int64   │\n│ BloodPressure            │ Count      │ Int64   │\n│ SkinThickness            │ Count      │ Int64   │\n│ Insulin                  │ Count      │ Int64   │\n│ BMI                      │ Continuous │ Float64 │\n│ DiabetesPedigreeFunction │ Continuous │ Float64 │\n│ Age                      │ Count      │ Int64   │\n└──────────────────────────┴────────────┴─────────┘"
  },
  {
    "objectID": "category/classification/2-diabetes-svm-classficiation.html#mlj-workflow",
    "href": "category/classification/2-diabetes-svm-classficiation.html#mlj-workflow",
    "title": "2-svm-diabetes-classfication",
    "section": "3. MLJ workflow",
    "text": "3. MLJ workflow\n\n3.1 defin model\n\n\nCode\nSVC = @load SVC pkg=LIBSVM\n#define kernel function,evaulate  kernelfunctions methods\nkernels=[PolynomialKernel(; degree=2, c=1), \n         SqExponentialKernel(),\n         NeuralNetworkKernel(),\n         LinearKernel(;c=1.0)\n]\n\nsvc_mdls = [SVC(;kernel=k) for  k in kernels]\nsvcs = [machine(model, Xtrain, ytrain;scitype_check_level=0) for model in svc_mdls]\n[fit!(svc) for svc in svcs]\n\n\n[ Info: For silent loading, specify `verbosity=0`. \n[ Info: Training machine(SVC(kernel = Polynomial Kernel (c = 1, degree = 2), …), …).\n\nWARNING: reaching max number of iterations\n[ Info: Training machine(SVC(kernel = Squared Exponential Kernel (metric = Distances.Euclidean(0.0)), …), …).\n[ Info: Training machine(SVC(kernel = Neural Network Kernel, …), …).\n[ Info: Training machine(SVC(kernel = Linear Kernel (c = 1.0), …), …).\n\nWARNING: reaching max number of iterations\n\n\nimport MLJLIBSVMInterface ✔\n\n\n4-element Vector{Machine{MLJLIBSVMInterface.SVC, true}}:\n machine(SVC(kernel = Polynomial Kernel (c = 1, degree = 2), …), …)\n machine(SVC(kernel = Squared Exponential Kernel (metric = Distances.Euclidean(0.0)), …), …)\n machine(SVC(kernel = Neural Network Kernel, …), …)\n machine(SVC(kernel = Linear Kernel (c = 1.0), …), …)\n\n\n\n\n3.2 predict test\n\n\nCode\nfor (idx, str) in enumerate([\"Polynomial \",\"Gaussian\",\"NeuralNetwork\",\"Linear\"])\n    local yhat=predict(svcs[idx],Xtest)\n    local acc=accuracy(yhat,ytest) \n    @info \"$(str) kernel predict accuracy\"=&gt;acc   \nend\n\n\n[ Info: \"Polynomial  kernel predict accuracy\" =&gt; 0.47391304347826085\n[ Info: \"Gaussian kernel predict accuracy\" =&gt; 0.6434782608695652\n[ Info: \"NeuralNetwork kernel predict accuracy\" =&gt; 0.6478260869565218\n[ Info: \"Linear kernel predict accuracy\" =&gt; 0.7782608695652173"
  },
  {
    "objectID": "category/dimension-reduction/3-olivetti-face.html",
    "href": "category/dimension-reduction/3-olivetti-face.html",
    "title": "3-olivetti-face",
    "section": "",
    "text": "Code\ninclude(\"./olivetti-face-code/1-dataprocessing.jl\")\n\nimport MLJ: transform, inverse_transform\nusing MLJ,DataFrames,CSV,Random,JLSO,GLMakie\nRandom.seed!(4545343)\n\n\nTaskLocalRNG()"
  },
  {
    "objectID": "category/dimension-reduction/3-olivetti-face.html#load-package",
    "href": "category/dimension-reduction/3-olivetti-face.html#load-package",
    "title": "3-olivetti-face",
    "section": "",
    "text": "Code\ninclude(\"./olivetti-face-code/1-dataprocessing.jl\")\n\nimport MLJ: transform, inverse_transform\nusing MLJ,DataFrames,CSV,Random,JLSO,GLMakie\nRandom.seed!(4545343)\n\n\nTaskLocalRNG()"
  },
  {
    "objectID": "category/dimension-reduction/3-olivetti-face.html#import-data",
    "href": "category/dimension-reduction/3-olivetti-face.html#import-data",
    "title": "3-olivetti-face",
    "section": "2. import data",
    "text": "2. import data\n\n\nCode\n(Xtrain, Xtest), (ytrain, ytest)=load_olivetti_faces()\n\n\n\n((320×4096 DataFrame\n Row │ x1         x2        x3         x4        x5        x6        x7        ⋯\n     │ Float64    Float64   Float64    Float64   Float64   Float64   Float64   ⋯\n─────┼──────────────────────────────────────────────────────────────────────────\n   1 │ 0.595041   0.640496  0.615702   0.644628  0.68595   0.72314   0.731405  ⋯\n   2 │ 0.103306   0.219008  0.177686   0.219008  0.392562  0.57438   0.669422\n   3 │ 0.289256   0.338843  0.417355   0.504132  0.553719  0.561983  0.582645\n   4 │ 0.528926   0.797521  0.826446   0.822314  0.822314  0.818182  0.805785\n   5 │ 0.161157   0.202479  0.268595   0.334711  0.384298  0.392562  0.396694  ⋯\n   6 │ 0.169422   0.293388  0.561983   0.677686  0.727273  0.756198  0.768595\n   7 │ 0.136364   0.177686  0.235537   0.289256  0.334711  0.363636  0.396694\n   8 │ 0.768595   0.756198  0.743802   0.743802  0.752066  0.747934  0.735537\n   9 │ 0.144628   0.210744  0.285124   0.342975  0.392562  0.404959  0.409091  ⋯\n  10 │ 0.566116   0.595041  0.603306   0.619835  0.636364  0.640496  0.661157\n  11 │ 0.524793   0.53719   0.578512   0.628099  0.669422  0.690083  0.68595\n  ⋮  │     ⋮         ⋮          ⋮         ⋮         ⋮         ⋮         ⋮      ⋱\n 311 │ 0.181818   0.338843  0.355372   0.404959  0.438017  0.458678  0.471074\n 312 │ 0.454545   0.528926  0.644628   0.747934  0.780992  0.780992  0.801653  ⋯\n 313 │ 0.553719   0.607438  0.636364   0.64876   0.652893  0.64876   0.673554\n 314 │ 0.0909091  0.136364  0.177686   0.231405  0.363636  0.504132  0.541322\n 315 │ 0.252066   0.252066  0.252066   0.252066  0.256198  0.239669  0.235537\n 316 │ 0.326446   0.483471  0.524793   0.599174  0.665289  0.702479  0.702479  ⋯\n 317 │ 0.53719    0.57438   0.553719   0.615702  0.38843   0.487603  0.690083\n 318 │ 0.128099   0.18595   0.247934   0.31405   0.38843   0.46281   0.520661\n 319 │ 0.586777   0.702479  0.731405   0.731405  0.743802  0.772727  0.793388\n 320 │ 0.136364   0.107438  0.0909091  0.115702  0.115702  0.119835  0.181818  ⋯\n                                               4089 columns and 299 rows omitted, 80×4096 DataFrame\n Row │ x1        x2        x3        x4        x5        x6        x7        x ⋯\n     │ Float64   Float64   Float64   Float64   Float64   Float64   Float64   F ⋯\n─────┼──────────────────────────────────────────────────────────────────────────\n   1 │ 0.219008  0.235537  0.252066  0.326446  0.392562  0.553719  0.714876  0 ⋯\n   2 │ 0.194215  0.268595  0.367769  0.487603  0.545455  0.561983  0.578512  0\n   3 │ 0.210744  0.206612  0.194215  0.181818  0.219008  0.239669  0.256198  0\n   4 │ 0.392562  0.475207  0.661157  0.590909  0.471074  0.545455  0.673554  0\n   5 │ 0.719008  0.727273  0.72314   0.714876  0.72314   0.731405  0.739669  0 ⋯\n   6 │ 0.429752  0.458678  0.549587  0.623967  0.673554  0.714876  0.72314   0\n   7 │ 0.289256  0.157025  0.14876   0.190083  0.169422  0.194215  0.404959  0\n   8 │ 0.628099  0.665289  0.68595   0.694215  0.719008  0.731405  0.752066  0\n   9 │ 0.479339  0.549587  0.628099  0.690083  0.677686  0.652893  0.640496  0 ⋯\n  10 │ 0.677686  0.677686  0.681818  0.706612  0.731405  0.739669  0.756198  0\n  11 │ 0.123967  0.132231  0.11157   0.11157   0.119835  0.136364  0.136364  0\n  ⋮  │    ⋮         ⋮         ⋮         ⋮         ⋮         ⋮         ⋮        ⋱\n  71 │ 0.123967  0.128099  0.115702  0.136364  0.115702  0.107438  0.115702  0\n  72 │ 0.384298  0.22314   0.22314   0.305785  0.429752  0.508265  0.557851  0 ⋯\n  73 │ 0.409091  0.590909  0.657025  0.681818  0.694215  0.731405  0.760331  0\n  74 │ 0.487603  0.330578  0.252066  0.38843   0.785124  0.789256  0.780992  0\n  75 │ 0.285124  0.285124  0.272727  0.214876  0.169422  0.165289  0.264463  0\n  76 │ 0.136364  0.132231  0.123967  0.119835  0.11157   0.128099  0.132231  0 ⋯\n  77 │ 0.243802  0.243802  0.247934  0.247934  0.252066  0.256198  0.256198  0\n  78 │ 0.603306  0.586777  0.541322  0.603306  0.603306  0.607438  0.64876   0\n  79 │ 0.772727  0.764463  0.752066  0.764463  0.785124  0.793388  0.797521  0\n  80 │ 0.475207  0.491736  0.5       0.512397  0.524793  0.528926  0.545455  0 ⋯\n                                                4089 columns and 59 rows omitted), (CategoricalArrays.CategoricalValue{Int64, UInt32}[27, 3, 39, 10, 23, 24, 23, 30, 23, 14  …  21, 26, 5, 35, 28, 9, 31, 0, 15, 37], CategoricalArrays.CategoricalValue{Int64, UInt32}[6, 35, 6, 31, 5, 4, 3, 2, 19, 4  …  32, 29, 22, 36, 12, 32, 16, 14, 3, 20]))"
  },
  {
    "objectID": "category/dimension-reduction/3-olivetti-face.html#trainsave-model",
    "href": "category/dimension-reduction/3-olivetti-face.html#trainsave-model",
    "title": "3-olivetti-face",
    "section": "3. train&save model",
    "text": "3. train&save model\n\n\nCode\n    PCA = @load PCA pkg=MultivariateStats\n    function  make_model(Xtr)\n    return (dim)-&gt;begin\n        model = PCA(maxoutdim=dim)\n        mach = machine(model, Xtr) |&gt; fit!\n        try\n            JLSO.save(\"./olivetti-face-code/models/of-model-$(dim)pcs.jlso\",:pca=&gt;mach)\n            @info \"$(dim) dimension pca model saved\"\n        catch e\n            @warn \"$(e) has problem\"\n        end\n    end\nend\nmake_ol_model=make_model(Xtrain)\nmake_ol_model.([1,2,3,100])\n\n\nimport MLJMultivariateStatsInterface ✔\n\n\n[ Info: For silent loading, specify `verbosity=0`. \n[ Info: Training machine(PCA(maxoutdim = 1, …), …).\n[ Info: 1 dimension pca model saved\n[ Info: Training machine(PCA(maxoutdim = 2, …), …).\n[ Info: 2 dimension pca model saved\n[ Info: Training machine(PCA(maxoutdim = 3, …), …).\n[ Info: 3 dimension pca model saved\n[ Info: Training machine(PCA(maxoutdim = 100, …), …).\n[ Info: 100 dimension pca model saved\n\n\n4-element Vector{Nothing}:\n nothing\n nothing\n nothing\n nothing"
  },
  {
    "objectID": "category/dimension-reduction/3-olivetti-face.html#imgs-project-to-low-dimension-feature-space",
    "href": "category/dimension-reduction/3-olivetti-face.html#imgs-project-to-low-dimension-feature-space",
    "title": "3-olivetti-face",
    "section": "4. imgs project to low dimension feature space",
    "text": "4. imgs project to low dimension feature space\n第三行是降维到 100的图片, 最后一行是原始图片\n\n\nCode\ninclude(\"./olivetti-face-code/3-transform-reconstruct-methods.jl\")\ncat=ytrain|&gt;Array|&gt;levels\nrows,cols=size(Xtrain)\n\npick20=rand(1:rows,20)\npickXtrain=Xtrain[pick20,:]\npickytrain=ytrain[pick20]\n\npcaData=transform_to_2d(pickXtrain)\nreconstructImgs=reconstruct_data(pcaData)\n\npcaData3=transform_to_3d(pickXtrain)\nreconstructImgs3=reconstruct_data(pcaData3)\n\ntransform_to_100d=transform_to_pcadata1(100)\npcaData100=transform_to_100d(pickXtrain)\nreconstructImgs100=reconstruct_data(pcaData100)\n\ndf=vcat(reconstructImgs,reconstructImgs3,reconstructImgs100,pickXtrain)\n\n\n[ Info: 2 pca proceeding...\n[ Info: imgs  reconstructing from 2 dimension\n[ Info: 3 pca proceeding...\n[ Info: imgs  reconstructing from 3 dimension\n[ Info: 100 pca proceeding...\n[ Info: imgs  reconstructing from 100 dimension\n\n\n80×4096 DataFrame3996 columns and 55 rows omitted\n\n\n\nRow\nx1\nx2\nx3\nx4\nx5\nx6\nx7\nx8\nx9\nx10\nx11\nx12\nx13\nx14\nx15\nx16\nx17\nx18\nx19\nx20\nx21\nx22\nx23\nx24\nx25\nx26\nx27\nx28\nx29\nx30\nx31\nx32\nx33\nx34\nx35\nx36\nx37\nx38\nx39\nx40\nx41\nx42\nx43\nx44\nx45\nx46\nx47\nx48\nx49\nx50\nx51\nx52\nx53\nx54\nx55\nx56\nx57\nx58\nx59\nx60\nx61\nx62\nx63\nx64\nx65\nx66\nx67\nx68\nx69\nx70\nx71\nx72\nx73\nx74\nx75\nx76\nx77\nx78\nx79\nx80\nx81\nx82\nx83\nx84\nx85\nx86\nx87\nx88\nx89\nx90\nx91\nx92\nx93\nx94\nx95\nx96\nx97\nx98\nx99\nx100\n⋯\n\n\n\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\n⋯\n\n\n\n\n1\n0.347498\n0.356433\n0.375264\n0.39954\n0.423023\n0.452978\n0.482274\n0.503785\n0.519725\n0.526426\n0.534472\n0.539163\n0.547752\n0.548612\n0.551928\n0.550904\n0.551664\n0.551791\n0.551633\n0.553009\n0.55499\n0.553559\n0.554242\n0.549705\n0.548917\n0.549303\n0.547618\n0.548721\n0.549941\n0.548578\n0.551999\n0.555619\n0.554749\n0.551963\n0.55098\n0.546373\n0.545315\n0.541134\n0.536055\n0.52792\n0.522628\n0.516831\n0.511274\n0.504655\n0.499186\n0.492699\n0.484203\n0.473755\n0.467841\n0.459916\n0.455482\n0.448347\n0.439979\n0.425104\n0.411437\n0.39844\n0.382408\n0.353639\n0.31849\n0.290463\n0.265268\n0.24943\n0.241055\n0.238127\n0.351332\n0.360198\n0.386193\n0.412789\n0.435357\n0.465185\n0.494089\n0.513728\n0.530586\n0.537144\n0.547946\n0.551217\n0.559378\n0.561427\n0.564977\n0.567751\n0.566366\n0.565085\n0.56924\n0.573174\n0.572161\n0.569604\n0.566815\n0.564914\n0.564524\n0.557596\n0.558352\n0.557152\n0.557154\n0.556278\n0.560522\n0.565832\n0.563424\n0.56306\n0.565221\n0.564248\n⋯\n\n\n2\n0.517323\n0.574701\n0.637824\n0.689222\n0.72297\n0.752127\n0.772595\n0.782153\n0.785537\n0.786146\n0.783327\n0.780133\n0.779794\n0.77967\n0.781213\n0.783158\n0.785168\n0.787799\n0.787414\n0.786651\n0.785654\n0.78473\n0.782535\n0.778389\n0.77507\n0.774482\n0.76858\n0.763289\n0.759652\n0.754611\n0.752834\n0.75236\n0.752247\n0.750873\n0.749019\n0.74466\n0.739307\n0.73623\n0.730776\n0.723315\n0.71545\n0.708287\n0.700588\n0.692186\n0.684442\n0.678492\n0.671835\n0.660478\n0.649346\n0.641482\n0.629974\n0.617705\n0.607259\n0.598648\n0.587301\n0.570553\n0.550199\n0.523786\n0.479269\n0.431485\n0.393957\n0.361259\n0.324836\n0.291902\n0.528134\n0.591601\n0.654956\n0.704336\n0.738806\n0.766358\n0.782817\n0.788165\n0.791302\n0.791121\n0.788372\n0.784759\n0.782904\n0.783305\n0.784144\n0.786172\n0.788562\n0.791007\n0.792148\n0.791703\n0.791692\n0.789554\n0.786332\n0.783966\n0.782476\n0.779952\n0.77532\n0.76947\n0.765259\n0.76029\n0.757802\n0.756306\n0.756551\n0.756472\n0.754564\n0.753349\n⋯\n\n\n3\n0.455477\n0.50084\n0.552429\n0.598455\n0.632881\n0.665276\n0.691794\n0.709252\n0.719167\n0.724507\n0.727599\n0.729214\n0.732596\n0.734849\n0.738048\n0.740483\n0.743513\n0.746724\n0.747753\n0.748665\n0.749276\n0.749044\n0.74841\n0.745529\n0.743752\n0.743925\n0.740204\n0.737341\n0.735166\n0.73202\n0.73156\n0.732154\n0.732169\n0.731377\n0.730696\n0.7277\n0.724582\n0.722473\n0.718304\n0.712185\n0.706117\n0.700641\n0.694664\n0.687884\n0.681925\n0.676942\n0.67095\n0.66163\n0.653022\n0.645484\n0.635839\n0.625602\n0.61635\n0.606994\n0.595671\n0.579182\n0.55828\n0.530665\n0.489583\n0.447237\n0.411732\n0.3807\n0.345804\n0.314192\n0.463803\n0.51405\n0.566475\n0.610999\n0.646321\n0.677711\n0.701414\n0.715647\n0.725785\n0.730841\n0.734172\n0.735186\n0.737466\n0.7405\n0.743267\n0.746521\n0.749267\n0.751957\n0.754201\n0.755408\n0.756075\n0.755203\n0.753704\n0.752193\n0.75157\n0.749529\n0.746794\n0.742832\n0.740361\n0.73699\n0.736155\n0.736794\n0.736799\n0.736963\n0.736569\n0.736201\n⋯\n\n\n4\n0.492681\n0.545701\n0.604579\n0.65418\n0.688534\n0.719206\n0.742301\n0.755276\n0.761411\n0.764097\n0.763782\n0.762652\n0.763831\n0.764809\n0.767088\n0.769348\n0.771877\n0.774853\n0.775133\n0.775105\n0.774789\n0.774207\n0.772673\n0.769139\n0.766482\n0.766228\n0.761244\n0.756928\n0.75385\n0.749606\n0.74831\n0.74823\n0.748198\n0.74714\n0.745818\n0.742113\n0.737702\n0.735115\n0.73026\n0.723455\n0.716371\n0.709971\n0.70303\n0.695349\n0.688389\n0.682912\n0.676623\n0.666207\n0.656128\n0.648421\n0.6376\n0.626154\n0.616217\n0.607426\n0.596155\n0.579425\n0.558691\n0.531773\n0.488627\n0.442875\n0.405965\n0.37359\n0.337113\n0.303975\n0.502506\n0.561214\n0.620418\n0.668125\n0.70333\n0.73264\n0.752192\n0.761361\n0.76744\n0.769558\n0.769319\n0.767711\n0.767541\n0.769146\n0.770824\n0.773414\n0.776077\n0.778742\n0.780323\n0.78054\n0.780879\n0.779354\n0.776937\n0.774965\n0.773855\n0.771683\n0.767801\n0.762719\n0.759217\n0.754892\n0.753002\n0.752331\n0.752536\n0.75258\n0.751278\n0.750458\n⋯\n\n\n5\n0.29635\n0.316432\n0.342945\n0.379661\n0.420254\n0.463932\n0.508857\n0.550194\n0.578874\n0.598902\n0.619163\n0.635091\n0.648517\n0.658904\n0.667377\n0.67265\n0.679779\n0.685978\n0.69198\n0.698093\n0.70337\n0.705796\n0.709692\n0.711473\n0.714286\n0.716825\n0.719362\n0.722845\n0.724127\n0.726413\n0.728762\n0.731683\n0.732428\n0.734233\n0.737424\n0.739393\n0.742698\n0.744453\n0.744741\n0.743661\n0.743079\n0.743139\n0.742534\n0.740902\n0.740493\n0.739163\n0.736219\n0.733849\n0.732359\n0.726005\n0.720441\n0.715595\n0.709853\n0.700122\n0.689728\n0.672796\n0.648359\n0.61731\n0.585088\n0.554974\n0.522202\n0.490979\n0.451311\n0.413481\n0.298332\n0.32124\n0.34822\n0.383696\n0.426408\n0.470685\n0.51574\n0.556524\n0.58668\n0.607998\n0.628121\n0.643165\n0.656573\n0.668414\n0.677084\n0.68445\n0.689845\n0.694771\n0.699857\n0.705373\n0.708829\n0.712634\n0.717139\n0.718512\n0.720587\n0.721878\n0.723959\n0.725047\n0.727263\n0.728109\n0.73073\n0.736514\n0.736631\n0.737769\n0.741301\n0.743875\n⋯\n\n\n6\n0.273376\n0.291233\n0.315289\n0.351801\n0.394404\n0.440457\n0.488757\n0.53444\n0.566325\n0.589109\n0.612345\n0.630829\n0.645824\n0.657897\n0.667388\n0.673468\n0.681562\n0.68857\n0.695628\n0.702718\n0.708802\n0.711833\n0.716513\n0.719324\n0.722957\n0.72594\n0.729544\n0.733969\n0.735672\n0.738883\n0.741491\n0.744642\n0.745594\n0.748051\n0.752019\n0.755072\n0.759475\n0.762135\n0.763357\n0.763406\n0.763834\n0.764994\n0.765403\n0.764761\n0.765395\n0.764887\n0.762721\n0.761787\n0.761482\n0.755387\n0.750232\n0.746205\n0.741081\n0.731685\n0.721646\n0.704368\n0.678884\n0.647252\n0.616316\n0.587522\n0.554519\n0.522137\n0.47958\n0.438419\n0.274456\n0.295104\n0.319089\n0.354129\n0.399222\n0.446121\n0.494946\n0.540495\n0.574049\n0.598419\n0.621257\n0.638863\n0.654002\n0.667628\n0.677388\n0.68559\n0.691805\n0.69746\n0.702958\n0.709111\n0.713233\n0.718073\n0.723841\n0.725804\n0.728387\n0.730687\n0.733447\n0.735313\n0.738258\n0.73974\n0.742658\n0.749098\n0.749415\n0.750782\n0.754889\n0.758079\n⋯\n\n\n7\n0.389424\n0.423229\n0.463541\n0.504851\n0.541002\n0.577523\n0.611146\n0.637846\n0.65518\n0.666142\n0.675991\n0.683181\n0.690643\n0.695892\n0.701089\n0.704405\n0.708857\n0.713027\n0.715869\n0.71877\n0.721219\n0.721924\n0.723074\n0.721862\n0.721873\n0.722951\n0.721706\n0.721459\n0.720776\n0.71978\n0.720595\n0.722235\n0.722477\n0.722556\n0.72332\n0.72211\n0.721532\n0.720768\n0.718232\n0.713904\n0.709951\n0.706548\n0.702623\n0.697796\n0.69396\n0.690273\n0.685295\n0.678537\n0.672766\n0.665653\n0.657837\n0.649807\n0.64193\n0.632128\n0.621026\n0.604562\n0.582594\n0.553619\n0.51621\n0.479274\n0.445369\n0.415104\n0.379869\n0.347492\n0.395106\n0.432745\n0.474102\n0.51422\n0.551629\n0.587799\n0.619853\n0.644412\n0.66248\n0.673761\n0.683846\n0.690283\n0.69709\n0.703395\n0.708434\n0.713215\n0.716733\n0.720049\n0.723472\n0.726457\n0.728084\n0.728886\n0.729583\n0.729139\n0.729548\n0.728496\n0.727772\n0.72587\n0.725305\n0.723664\n0.724415\n0.727254\n0.727169\n0.727672\n0.728901\n0.729611\n⋯\n\n\n8\n0.436103\n0.474321\n0.519536\n0.561172\n0.593157\n0.624795\n0.651505\n0.669306\n0.68009\n0.685402\n0.689172\n0.69113\n0.695395\n0.697179\n0.70029\n0.701935\n0.704398\n0.706894\n0.707566\n0.708464\n0.709265\n0.708722\n0.708269\n0.704938\n0.703272\n0.703439\n0.700014\n0.697851\n0.696319\n0.693433\n0.693731\n0.694914\n0.694726\n0.693458\n0.69263\n0.689188\n0.686367\n0.683738\n0.679282\n0.672629\n0.666607\n0.660945\n0.654942\n0.648085\n0.64211\n0.636732\n0.630147\n0.620439\n0.612247\n0.604602\n0.595969\n0.586271\n0.577131\n0.566618\n0.554781\n0.539038\n0.519239\n0.491455\n0.451434\n0.411848\n0.378459\n0.350638\n0.32144\n0.296014\n0.443617\n0.485718\n0.533112\n0.574047\n0.606519\n0.637303\n0.661646\n0.676451\n0.687578\n0.692602\n0.69715\n0.69834\n0.701622\n0.704259\n0.707065\n0.71013\n0.711947\n0.713751\n0.716338\n0.718028\n0.718281\n0.716953\n0.715053\n0.713398\n0.712766\n0.709623\n0.707521\n0.704033\n0.701984\n0.699049\n0.699212\n0.700725\n0.700219\n0.700251\n0.700312\n0.699754\n⋯\n\n\n9\n0.317283\n0.332209\n0.355093\n0.386241\n0.419365\n0.457116\n0.495344\n0.528193\n0.551452\n0.56576\n0.580815\n0.59194\n0.603336\n0.609612\n0.615867\n0.618397\n0.622763\n0.62632\n0.62966\n0.63374\n0.637613\n0.638367\n0.640894\n0.639941\n0.641215\n0.642829\n0.64357\n0.646069\n0.647357\n0.648092\n0.65094\n0.654192\n0.654234\n0.654044\n0.655436\n0.65456\n0.656009\n0.65519\n0.65316\n0.649025\n0.646424\n0.643961\n0.64123\n0.637455\n0.634873\n0.63131\n0.625953\n0.620097\n0.61673\n0.609697\n0.60467\n0.59887\n0.592007\n0.580009\n0.568184\n0.552979\n0.532206\n0.502127\n0.468704\n0.43963\n0.41022\n0.385766\n0.359822\n0.337291\n0.320017\n0.336474\n0.362769\n0.394247\n0.428167\n0.466212\n0.504371\n0.536112\n0.560614\n0.575597\n0.591785\n0.601786\n0.612995\n0.620614\n0.627089\n0.632475\n0.634913\n0.637129\n0.641833\n0.646696\n0.648213\n0.649264\n0.650618\n0.650579\n0.651596\n0.649303\n0.650848\n0.65098\n0.652268\n0.652398\n0.655767\n0.661394\n0.660401\n0.660887\n0.663855\n0.664896\n⋯\n\n\n10\n0.287526\n0.289496\n0.300971\n0.32379\n0.35161\n0.38716\n0.424685\n0.456812\n0.480717\n0.494097\n0.509505\n0.520473\n0.533061\n0.537907\n0.543671\n0.544433\n0.547409\n0.549342\n0.551665\n0.555409\n0.559388\n0.559357\n0.561982\n0.559843\n0.561067\n0.56253\n0.563498\n0.567038\n0.56942\n0.570358\n0.574575\n0.578879\n0.578469\n0.577161\n0.578027\n0.575953\n0.577621\n0.575521\n0.572645\n0.567133\n0.5643\n0.561131\n0.558029\n0.553792\n0.550851\n0.546271\n0.539531\n0.53248\n0.529533\n0.522213\n0.518992\n0.513963\n0.507117\n0.4928\n0.47988\n0.466211\n0.44788\n0.417661\n0.385861\n0.361643\n0.336354\n0.318406\n0.304273\n0.294626\n0.288994\n0.290593\n0.308217\n0.332971\n0.360687\n0.396744\n0.43493\n0.466252\n0.491568\n0.505523\n0.523176\n0.5327\n0.545277\n0.551571\n0.557775\n0.562533\n0.562936\n0.563227\n0.568455\n0.57404\n0.574553\n0.574405\n0.574592\n0.57409\n0.57493\n0.570208\n0.572749\n0.573541\n0.575403\n0.576166\n0.581349\n0.588441\n0.586407\n0.586567\n0.590222\n0.590704\n⋯\n\n\n11\n0.441812\n0.486114\n0.536457\n0.582573\n0.6184\n0.652345\n0.681004\n0.701212\n0.713125\n0.720222\n0.725175\n0.728401\n0.732738\n0.736088\n0.739939\n0.742928\n0.746601\n0.750363\n0.752082\n0.753617\n0.754733\n0.754901\n0.754758\n0.752555\n0.751295\n0.751751\n0.748695\n0.746396\n0.744458\n0.741888\n0.741555\n0.742266\n0.742423\n0.74207\n0.74189\n0.739608\n0.737174\n0.735668\n0.732108\n0.726734\n0.721307\n0.716542\n0.711212\n0.705066\n0.699772\n0.695332\n0.689866\n0.681479\n0.673606\n0.666237\n0.656802\n0.64706\n0.638196\n0.629112\n0.61804\n0.601294\n0.579669\n0.551692\n0.511375\n0.469733\n0.433975\n0.402045\n0.365024\n0.330983\n0.449603\n0.498818\n0.549586\n0.594012\n0.630993\n0.664083\n0.690154\n0.707395\n0.719647\n0.726649\n0.731648\n0.734285\n0.737617\n0.741808\n0.745267\n0.749064\n0.752378\n0.755577\n0.758066\n0.759654\n0.760766\n0.760576\n0.759902\n0.758774\n0.758474\n0.757131\n0.754797\n0.751307\n0.749279\n0.746291\n0.745596\n0.746608\n0.746767\n0.747083\n0.747032\n0.747067\n⋯\n\n\n12\n0.554789\n0.629173\n0.70723\n0.769672\n0.810644\n0.842935\n0.86464\n0.875544\n0.878358\n0.880445\n0.877424\n0.874667\n0.872885\n0.874811\n0.877097\n0.881463\n0.885406\n0.890264\n0.891325\n0.891096\n0.89003\n0.890202\n0.887948\n0.885469\n0.882289\n0.881942\n0.875834\n0.869245\n0.864192\n0.858963\n0.855393\n0.853541\n0.854047\n0.854216\n0.853131\n0.85046\n0.844913\n0.843619\n0.839371\n0.833841\n0.826375\n0.820247\n0.813133\n0.805431\n0.798258\n0.793733\n0.788981\n0.779339\n0.767757\n0.760297\n0.746427\n0.733208\n0.722795\n0.717291\n0.707432\n0.688612\n0.664921\n0.638642\n0.592085\n0.537969\n0.494947\n0.453505\n0.401138\n0.350796\n0.567201\n0.650199\n0.724801\n0.783073\n0.825994\n0.856422\n0.873182\n0.879512\n0.881872\n0.883331\n0.878878\n0.876128\n0.872611\n0.874931\n0.876227\n0.879164\n0.884329\n0.889397\n0.889879\n0.888532\n0.889913\n0.889461\n0.887902\n0.886203\n0.884994\n0.885786\n0.879891\n0.873234\n0.868325\n0.862573\n0.857703\n0.85432\n0.855965\n0.856339\n0.85357\n0.853154\n⋯\n\n\n13\n0.396561\n0.437814\n0.484407\n0.53119\n0.572021\n0.611343\n0.647322\n0.676931\n0.695621\n0.708744\n0.720017\n0.728739\n0.736278\n0.743426\n0.74952\n0.754473\n0.760397\n0.766106\n0.77022\n0.773892\n0.77672\n0.77829\n0.779812\n0.77997\n0.780471\n0.781899\n0.781098\n0.780677\n0.779496\n0.77888\n0.778922\n0.779984\n0.780644\n0.781837\n0.783388\n0.783587\n0.783473\n0.784074\n0.782626\n0.779853\n0.77662\n0.774304\n0.771195\n0.767229\n0.764216\n0.761671\n0.758054\n0.752899\n0.747508\n0.740732\n0.731933\n0.723844\n0.716299\n0.708239\n0.69807\n0.680383\n0.656193\n0.626986\n0.589206\n0.549749\n0.512952\n0.477676\n0.432906\n0.390029\n0.402588\n0.448932\n0.494433\n0.538818\n0.581717\n0.620685\n0.654824\n0.682324\n0.701743\n0.715417\n0.726034\n0.734221\n0.741077\n0.749267\n0.755097\n0.760765\n0.766106\n0.77112\n0.774421\n0.777277\n0.779949\n0.782133\n0.784318\n0.784514\n0.785325\n0.786465\n0.785452\n0.783541\n0.782999\n0.781288\n0.780988\n0.783211\n0.783936\n0.784784\n0.785874\n0.787304\n⋯\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋱\n\n\n69\n0.280992\n0.194215\n0.301653\n0.487603\n0.533058\n0.541322\n0.541322\n0.582645\n0.615702\n0.603306\n0.603306\n0.657025\n0.706612\n0.727273\n0.710744\n0.727273\n0.694215\n0.702479\n0.731405\n0.768595\n0.805785\n0.801653\n0.81405\n0.81405\n0.809917\n0.818182\n0.809917\n0.818182\n0.81405\n0.822314\n0.818182\n0.81405\n0.822314\n0.81405\n0.818182\n0.822314\n0.81405\n0.822314\n0.818182\n0.822314\n0.818182\n0.809917\n0.81405\n0.818182\n0.81405\n0.809917\n0.793388\n0.780992\n0.789256\n0.760331\n0.756198\n0.772727\n0.764463\n0.719008\n0.677686\n0.640496\n0.615702\n0.595041\n0.334711\n0.289256\n0.206612\n0.198347\n0.318182\n0.376033\n0.252066\n0.194215\n0.285124\n0.458678\n0.516529\n0.528926\n0.516529\n0.570248\n0.615702\n0.619835\n0.590909\n0.64876\n0.706612\n0.727273\n0.727273\n0.72314\n0.698347\n0.702479\n0.727273\n0.772727\n0.797521\n0.805785\n0.822314\n0.818182\n0.818182\n0.822314\n0.830578\n0.822314\n0.822314\n0.822314\n0.818182\n0.818182\n0.826446\n0.81405\n0.826446\n0.822314\n⋯\n\n\n70\n0.123967\n0.0991735\n0.123967\n0.107438\n0.107438\n0.128099\n0.128099\n0.132231\n0.14876\n0.14876\n0.161157\n0.181818\n0.177686\n0.173554\n0.181818\n0.173554\n0.165289\n0.18595\n0.152893\n0.169422\n0.157025\n0.14876\n0.161157\n0.165289\n0.194215\n0.194215\n0.210744\n0.231405\n0.260331\n0.280992\n0.305785\n0.322314\n0.322314\n0.326446\n0.326446\n0.342975\n0.367769\n0.38843\n0.38843\n0.384298\n0.429752\n0.450413\n0.466942\n0.466942\n0.471074\n0.46281\n0.466942\n0.466942\n0.479339\n0.487603\n0.495868\n0.495868\n0.458678\n0.450413\n0.433884\n0.429752\n0.384298\n0.342975\n0.305785\n0.247934\n0.227273\n0.198347\n0.181818\n0.165289\n0.115702\n0.103306\n0.128099\n0.115702\n0.128099\n0.119835\n0.140496\n0.157025\n0.161157\n0.169422\n0.157025\n0.173554\n0.190083\n0.190083\n0.18595\n0.18595\n0.165289\n0.18595\n0.161157\n0.18595\n0.177686\n0.173554\n0.173554\n0.198347\n0.190083\n0.198347\n0.22314\n0.227273\n0.256198\n0.243802\n0.260331\n0.280992\n0.309917\n0.342975\n0.359504\n0.355372\n⋯\n\n\n71\n0.603306\n0.632231\n0.652893\n0.673554\n0.677686\n0.698347\n0.731405\n0.743802\n0.752066\n0.77686\n0.780992\n0.789256\n0.793388\n0.789256\n0.785124\n0.793388\n0.797521\n0.81405\n0.81405\n0.818182\n0.822314\n0.818182\n0.822314\n0.818182\n0.830578\n0.826446\n0.834711\n0.826446\n0.822314\n0.826446\n0.822314\n0.818182\n0.818182\n0.830578\n0.834711\n0.830578\n0.822314\n0.822314\n0.818182\n0.805785\n0.801653\n0.797521\n0.801653\n0.797521\n0.793388\n0.793388\n0.789256\n0.772727\n0.760331\n0.77686\n0.77686\n0.772727\n0.764463\n0.739669\n0.72314\n0.714876\n0.694215\n0.636364\n0.590909\n0.578512\n0.557851\n0.516529\n0.438017\n0.309917\n0.590909\n0.619835\n0.64876\n0.673554\n0.673554\n0.698347\n0.727273\n0.747934\n0.764463\n0.768595\n0.77686\n0.780992\n0.789256\n0.780992\n0.780992\n0.789256\n0.785124\n0.797521\n0.81405\n0.805785\n0.818182\n0.822314\n0.809917\n0.809917\n0.826446\n0.822314\n0.830578\n0.822314\n0.822314\n0.830578\n0.830578\n0.818182\n0.81405\n0.830578\n0.834711\n0.822314\n⋯\n\n\n72\n0.392562\n0.524793\n0.619835\n0.690083\n0.739669\n0.772727\n0.801653\n0.818182\n0.826446\n0.834711\n0.826446\n0.834711\n0.834711\n0.830578\n0.838843\n0.838843\n0.834711\n0.838843\n0.842975\n0.847107\n0.85124\n0.842975\n0.85124\n0.847107\n0.85124\n0.85124\n0.842975\n0.842975\n0.842975\n0.842975\n0.838843\n0.834711\n0.838843\n0.834711\n0.838843\n0.838843\n0.838843\n0.838843\n0.834711\n0.830578\n0.822314\n0.818182\n0.801653\n0.797521\n0.789256\n0.797521\n0.77686\n0.760331\n0.714876\n0.644628\n0.590909\n0.561983\n0.491736\n0.429752\n0.347107\n0.347107\n0.276859\n0.173554\n0.173554\n0.173554\n0.202479\n0.202479\n0.214876\n0.252066\n0.475207\n0.61157\n0.673554\n0.714876\n0.752066\n0.77686\n0.81405\n0.822314\n0.826446\n0.834711\n0.834711\n0.834711\n0.830578\n0.826446\n0.834711\n0.834711\n0.834711\n0.838843\n0.847107\n0.847107\n0.847107\n0.847107\n0.842975\n0.842975\n0.842975\n0.842975\n0.838843\n0.842975\n0.847107\n0.842975\n0.842975\n0.838843\n0.838843\n0.838843\n0.838843\n0.842975\n⋯\n\n\n73\n0.512397\n0.557851\n0.619835\n0.652893\n0.665289\n0.681818\n0.694215\n0.739669\n0.760331\n0.780992\n0.789256\n0.785124\n0.785124\n0.793388\n0.793388\n0.793388\n0.797521\n0.793388\n0.805785\n0.81405\n0.81405\n0.81405\n0.826446\n0.834711\n0.834711\n0.838843\n0.830578\n0.838843\n0.838843\n0.842975\n0.847107\n0.85124\n0.85124\n0.855372\n0.85124\n0.847107\n0.85124\n0.847107\n0.838843\n0.842975\n0.830578\n0.818182\n0.81405\n0.822314\n0.809917\n0.826446\n0.81405\n0.809917\n0.81405\n0.81405\n0.809917\n0.805785\n0.801653\n0.793388\n0.780992\n0.752066\n0.727273\n0.694215\n0.661157\n0.582645\n0.487603\n0.421488\n0.338843\n0.342975\n0.53719\n0.586777\n0.623967\n0.628099\n0.64876\n0.661157\n0.694215\n0.735537\n0.760331\n0.785124\n0.780992\n0.785124\n0.789256\n0.793388\n0.789256\n0.797521\n0.801653\n0.805785\n0.81405\n0.81405\n0.81405\n0.818182\n0.822314\n0.830578\n0.838843\n0.834711\n0.834711\n0.830578\n0.847107\n0.842975\n0.847107\n0.85124\n0.85124\n0.85124\n0.85124\n0.85124\n⋯\n\n\n74\n0.260331\n0.194215\n0.144628\n0.31405\n0.483471\n0.508265\n0.524793\n0.57438\n0.595041\n0.615702\n0.623967\n0.628099\n0.636364\n0.640496\n0.644628\n0.644628\n0.669422\n0.669422\n0.661157\n0.661157\n0.669422\n0.681818\n0.669422\n0.673554\n0.68595\n0.698347\n0.694215\n0.710744\n0.681818\n0.702479\n0.694215\n0.702479\n0.694215\n0.694215\n0.702479\n0.706612\n0.714876\n0.739669\n0.756198\n0.760331\n0.768595\n0.752066\n0.735537\n0.743802\n0.752066\n0.731405\n0.727273\n0.714876\n0.714876\n0.714876\n0.710744\n0.706612\n0.698347\n0.690083\n0.677686\n0.677686\n0.677686\n0.681818\n0.677686\n0.690083\n0.657025\n0.661157\n0.669422\n0.652893\n0.268595\n0.194215\n0.128099\n0.322314\n0.483471\n0.520661\n0.553719\n0.582645\n0.586777\n0.615702\n0.628099\n0.628099\n0.636364\n0.640496\n0.64876\n0.665289\n0.681818\n0.681818\n0.673554\n0.677686\n0.673554\n0.694215\n0.681818\n0.681818\n0.690083\n0.694215\n0.698347\n0.68595\n0.690083\n0.698347\n0.690083\n0.706612\n0.710744\n0.702479\n0.698347\n0.702479\n⋯\n\n\n75\n0.661157\n0.661157\n0.665289\n0.669422\n0.702479\n0.727273\n0.743802\n0.756198\n0.768595\n0.760331\n0.756198\n0.752066\n0.756198\n0.760331\n0.768595\n0.772727\n0.785124\n0.789256\n0.789256\n0.789256\n0.780992\n0.772727\n0.768595\n0.768595\n0.764463\n0.764463\n0.764463\n0.768595\n0.756198\n0.756198\n0.743802\n0.739669\n0.747934\n0.743802\n0.731405\n0.727273\n0.719008\n0.714876\n0.706612\n0.702479\n0.698347\n0.694215\n0.690083\n0.681818\n0.677686\n0.657025\n0.636364\n0.632231\n0.619835\n0.603306\n0.590909\n0.578512\n0.566116\n0.566116\n0.545455\n0.53719\n0.516529\n0.479339\n0.450413\n0.429752\n0.417355\n0.409091\n0.367769\n0.252066\n0.652893\n0.652893\n0.652893\n0.661157\n0.673554\n0.698347\n0.727273\n0.735537\n0.756198\n0.756198\n0.747934\n0.743802\n0.747934\n0.764463\n0.772727\n0.780992\n0.789256\n0.793388\n0.797521\n0.801653\n0.797521\n0.789256\n0.780992\n0.780992\n0.77686\n0.77686\n0.768595\n0.77686\n0.764463\n0.760331\n0.764463\n0.764463\n0.764463\n0.756198\n0.747934\n0.727273\n⋯\n\n\n76\n0.743802\n0.756198\n0.764463\n0.772727\n0.780992\n0.785124\n0.797521\n0.801653\n0.801653\n0.81405\n0.818182\n0.81405\n0.822314\n0.826446\n0.830578\n0.834711\n0.834711\n0.838843\n0.842975\n0.847107\n0.842975\n0.847107\n0.847107\n0.847107\n0.85124\n0.85124\n0.847107\n0.842975\n0.842975\n0.834711\n0.830578\n0.822314\n0.818182\n0.818182\n0.818182\n0.822314\n0.822314\n0.822314\n0.826446\n0.826446\n0.818182\n0.805785\n0.797521\n0.789256\n0.793388\n0.789256\n0.77686\n0.764463\n0.764463\n0.743802\n0.735537\n0.72314\n0.714876\n0.706612\n0.690083\n0.661157\n0.636364\n0.599174\n0.528926\n0.512397\n0.293388\n0.0743802\n0.239669\n0.219008\n0.739669\n0.752066\n0.760331\n0.77686\n0.780992\n0.789256\n0.793388\n0.801653\n0.805785\n0.81405\n0.818182\n0.81405\n0.826446\n0.830578\n0.834711\n0.834711\n0.838843\n0.842975\n0.842975\n0.847107\n0.847107\n0.847107\n0.847107\n0.842975\n0.842975\n0.85124\n0.85124\n0.847107\n0.838843\n0.830578\n0.834711\n0.826446\n0.81405\n0.81405\n0.818182\n0.822314\n⋯\n\n\n77\n0.202479\n0.256198\n0.322314\n0.450413\n0.57438\n0.665289\n0.714876\n0.768595\n0.797521\n0.81405\n0.826446\n0.830578\n0.830578\n0.834711\n0.834711\n0.834711\n0.830578\n0.838843\n0.838843\n0.838843\n0.842975\n0.842975\n0.847107\n0.842975\n0.85124\n0.85124\n0.847107\n0.847107\n0.842975\n0.842975\n0.838843\n0.842975\n0.842975\n0.838843\n0.838843\n0.838843\n0.830578\n0.830578\n0.826446\n0.822314\n0.818182\n0.809917\n0.801653\n0.789256\n0.797521\n0.780992\n0.727273\n0.652893\n0.578512\n0.528926\n0.46281\n0.338843\n0.305785\n0.338843\n0.276859\n0.210744\n0.202479\n0.247934\n0.227273\n0.214876\n0.268595\n0.239669\n0.210744\n0.194215\n0.22314\n0.297521\n0.376033\n0.508265\n0.61157\n0.673554\n0.727273\n0.77686\n0.809917\n0.822314\n0.826446\n0.826446\n0.830578\n0.834711\n0.830578\n0.834711\n0.830578\n0.834711\n0.842975\n0.842975\n0.842975\n0.847107\n0.847107\n0.847107\n0.855372\n0.85124\n0.847107\n0.85124\n0.842975\n0.842975\n0.838843\n0.838843\n0.838843\n0.842975\n0.842975\n0.838843\n⋯\n\n\n78\n0.338843\n0.458678\n0.681818\n0.772727\n0.785124\n0.81405\n0.838843\n0.85124\n0.847107\n0.85124\n0.855372\n0.855372\n0.85124\n0.85124\n0.847107\n0.847107\n0.85124\n0.847107\n0.847107\n0.838843\n0.834711\n0.826446\n0.822314\n0.822314\n0.805785\n0.785124\n0.768595\n0.760331\n0.752066\n0.735537\n0.735537\n0.764463\n0.760331\n0.756198\n0.756198\n0.756198\n0.747934\n0.752066\n0.739669\n0.735537\n0.714876\n0.710744\n0.706612\n0.710744\n0.706612\n0.694215\n0.690083\n0.681818\n0.673554\n0.673554\n0.665289\n0.64876\n0.640496\n0.644628\n0.644628\n0.623967\n0.603306\n0.595041\n0.553719\n0.512397\n0.491736\n0.433884\n0.177686\n0.190083\n0.371901\n0.516529\n0.72314\n0.789256\n0.780992\n0.809917\n0.847107\n0.855372\n0.859504\n0.859504\n0.855372\n0.859504\n0.85124\n0.855372\n0.859504\n0.859504\n0.863636\n0.859504\n0.859504\n0.85124\n0.842975\n0.834711\n0.834711\n0.830578\n0.822314\n0.801653\n0.780992\n0.764463\n0.752066\n0.731405\n0.727273\n0.747934\n0.772727\n0.764463\n0.756198\n0.768595\n⋯\n\n\n79\n0.516529\n0.46281\n0.280992\n0.252066\n0.247934\n0.367769\n0.57438\n0.615702\n0.661157\n0.615702\n0.681818\n0.702479\n0.735537\n0.739669\n0.743802\n0.768595\n0.789256\n0.793388\n0.797521\n0.81405\n0.822314\n0.822314\n0.826446\n0.830578\n0.830578\n0.834711\n0.838843\n0.834711\n0.834711\n0.834711\n0.826446\n0.830578\n0.830578\n0.830578\n0.834711\n0.834711\n0.830578\n0.830578\n0.830578\n0.822314\n0.826446\n0.818182\n0.81405\n0.809917\n0.801653\n0.801653\n0.797521\n0.785124\n0.772727\n0.747934\n0.739669\n0.731405\n0.719008\n0.714876\n0.702479\n0.690083\n0.665289\n0.644628\n0.623967\n0.603306\n0.582645\n0.578512\n0.541322\n0.603306\n0.516529\n0.450413\n0.293388\n0.243802\n0.235537\n0.396694\n0.566116\n0.632231\n0.652893\n0.64876\n0.694215\n0.719008\n0.752066\n0.764463\n0.768595\n0.789256\n0.801653\n0.805785\n0.809917\n0.822314\n0.822314\n0.822314\n0.830578\n0.830578\n0.830578\n0.826446\n0.822314\n0.826446\n0.826446\n0.826446\n0.822314\n0.818182\n0.826446\n0.830578\n0.838843\n0.838843\n⋯\n\n\n80\n0.5\n0.590909\n0.628099\n0.669422\n0.68595\n0.706612\n0.72314\n0.739669\n0.743802\n0.743802\n0.768595\n0.772727\n0.77686\n0.785124\n0.789256\n0.797521\n0.805785\n0.801653\n0.818182\n0.81405\n0.81405\n0.818182\n0.818182\n0.818182\n0.822314\n0.822314\n0.822314\n0.826446\n0.830578\n0.818182\n0.818182\n0.818182\n0.81405\n0.818182\n0.81405\n0.826446\n0.826446\n0.826446\n0.81405\n0.797521\n0.81405\n0.805785\n0.809917\n0.797521\n0.793388\n0.793388\n0.793388\n0.772727\n0.760331\n0.768595\n0.752066\n0.739669\n0.72314\n0.698347\n0.673554\n0.677686\n0.619835\n0.61157\n0.586777\n0.520661\n0.421488\n0.301653\n0.177686\n0.140496\n0.549587\n0.561983\n0.61157\n0.673554\n0.694215\n0.706612\n0.727273\n0.743802\n0.743802\n0.756198\n0.780992\n0.780992\n0.785124\n0.789256\n0.793388\n0.797521\n0.801653\n0.805785\n0.822314\n0.809917\n0.81405\n0.81405\n0.81405\n0.818182\n0.822314\n0.822314\n0.822314\n0.822314\n0.830578\n0.826446\n0.818182\n0.822314\n0.818182\n0.826446\n0.809917\n0.826446\n⋯\n\n\n\n\n\n\nplot reconstruct imgs\n\n\nCode\nfunction  plot_img(df)\n    \n    fig=Figure(resolution=(130*20,130*4))\n    \n    for i in 0:3\n        for j in 1:20\n            idx=i*20+j\n            ax=Axis(fig[i+1,j],yreversed=true)\n            img=df[idx,:]|&gt;Array|&gt;d-&gt;reshape(d,w,h)\n            image!(ax,img)\n            hidespines!(ax)\n            hidedecorations!(ax)\n        end\n    end\n\n    fig\n    #save(\"./imgs/reconstruct-of-face.png\",fig)\nend\n\n\nplot_img(df)"
  },
  {
    "objectID": "category/dimension-reduction/4-NIR-Spectra-Milk.html",
    "href": "category/dimension-reduction/4-NIR-Spectra-Milk.html",
    "title": "4-NIR-Spectra-Milk",
    "section": "",
    "text": "简介\n\n\n\n利用 PCA 对不同品种牛奶的近红外光谱数据进行降维处理\n在这里从 602d降维到2d,3d,然后利用SVC · MLJ 进行分类,绘制决策边界\n参考 :Classification of NIR spectra using Principal Component Analysis in Python"
  },
  {
    "objectID": "category/dimension-reduction/4-NIR-Spectra-Milk.html#load-package",
    "href": "category/dimension-reduction/4-NIR-Spectra-Milk.html#load-package",
    "title": "4-NIR-Spectra-Milk",
    "section": "1. load package",
    "text": "1. load package\n\n\nCode\ninclude(\"../utils.jl\")\nimport MLJ:transform,predict\nusing DataFrames,MLJ,CSV,MLJModelInterface,GLMakie"
  },
  {
    "objectID": "category/dimension-reduction/4-NIR-Spectra-Milk.html#data-digest",
    "href": "category/dimension-reduction/4-NIR-Spectra-Milk.html#data-digest",
    "title": "4-NIR-Spectra-Milk",
    "section": "2. data digest",
    "text": "2. data digest\n\n2.1 load csv=&gt;dataframe\n\n\nCode\ndf=load_csv(\"NIR-spectra-milk\")\nfirst(df,10)\n\n\n10×603 DataFrame503 columns omitted\n\n\n\nRow\nColumn1\nlabels\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n⋯\n\n\n\nString15\nInt64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\n⋯\n\n\n\n\n1\n1/02/2018\n1\n2.39753\n2.3942\n2.38895\n2.38128\n2.37191\n2.36094\n2.34909\n2.33675\n2.32383\n2.30971\n2.29375\n2.27532\n2.25373\n2.22825\n2.19869\n2.16501\n2.12755\n2.08735\n2.0453\n2.00258\n1.95983\n1.91818\n1.87829\n1.84078\n1.80598\n1.77438\n1.74615\n1.72117\n1.69931\n1.68041\n1.66405\n1.65001\n1.6378\n1.6275\n1.61876\n1.61132\n1.60516\n1.59983\n1.5951\n1.59059\n1.58612\n1.5818\n1.57757\n1.57357\n1.56972\n1.56607\n1.56265\n1.55942\n1.55642\n1.55372\n1.55133\n1.54911\n1.54703\n1.54519\n1.54358\n1.54237\n1.54159\n1.54116\n1.54116\n1.54145\n1.54202\n1.54291\n1.54406\n1.5453\n1.54653\n1.54758\n1.54866\n1.54986\n1.55122\n1.55296\n1.55495\n1.55694\n1.55884\n1.56038\n1.56144\n1.56212\n1.56237\n1.56225\n1.5615\n1.56006\n1.55796\n1.5552\n1.552\n1.54864\n1.54536\n1.54231\n1.53927\n1.53626\n1.53293\n1.52915\n1.52472\n1.51945\n1.51336\n1.50644\n1.49855\n1.48957\n1.47928\n1.46769\n⋯\n\n\n2\n1/02/2018.1\n1\n2.39953\n2.39672\n2.39168\n2.38328\n2.37282\n2.36116\n2.34854\n2.33635\n2.32436\n2.31153\n2.29693\n2.27919\n2.25795\n2.23234\n2.20204\n2.16763\n2.12913\n2.08767\n2.04446\n2.00054\n1.957\n1.91494\n1.87484\n1.83739\n1.80299\n1.77194\n1.74441\n1.72002\n1.69886\n1.68052\n1.66447\n1.65057\n1.63856\n1.62809\n1.61911\n1.61122\n1.6043\n1.59809\n1.59243\n1.58731\n1.58272\n1.57838\n1.57426\n1.57032\n1.56641\n1.56272\n1.5593\n1.5564\n1.55416\n1.5522\n1.55054\n1.54904\n1.54754\n1.54596\n1.54428\n1.54276\n1.54154\n1.5405\n1.54005\n1.54011\n1.54063\n1.54154\n1.54263\n1.54386\n1.54516\n1.54637\n1.54776\n1.54926\n1.55094\n1.55289\n1.55495\n1.55709\n1.55911\n1.56082\n1.56214\n1.56297\n1.56332\n1.56318\n1.56242\n1.56104\n1.55903\n1.55636\n1.55316\n1.54962\n1.54597\n1.54234\n1.53891\n1.53554\n1.53214\n1.52839\n1.52415\n1.51917\n1.51333\n1.50651\n1.49868\n1.48974\n1.47952\n1.46797\n⋯\n\n\n3\n1/02/2018.2\n1\n2.39647\n2.3936\n2.38845\n2.38099\n2.37132\n2.35993\n2.34811\n2.33635\n2.32446\n2.3115\n2.29619\n2.27764\n2.25522\n2.22877\n2.19835\n2.16399\n2.12632\n2.08603\n2.04386\n2.00081\n1.95794\n1.91628\n1.87625\n1.83868\n1.80421\n1.77314\n1.74554\n1.72122\n1.69974\n1.68103\n1.66475\n1.65072\n1.63884\n1.62889\n1.62055\n1.61334\n1.60698\n1.60136\n1.5961\n1.5911\n1.5863\n1.58153\n1.57689\n1.57237\n1.5682\n1.56448\n1.56114\n1.55825\n1.55571\n1.55338\n1.55137\n1.5495\n1.54781\n1.54615\n1.54467\n1.54339\n1.5424\n1.54185\n1.54178\n1.54207\n1.54268\n1.54334\n1.54407\n1.54484\n1.54569\n1.54667\n1.54784\n1.54923\n1.55093\n1.55288\n1.555\n1.55721\n1.55931\n1.56103\n1.56229\n1.56291\n1.56305\n1.56267\n1.56183\n1.5605\n1.55858\n1.55614\n1.55327\n1.5501\n1.54687\n1.54363\n1.54043\n1.53708\n1.53339\n1.52924\n1.52439\n1.51887\n1.51259\n1.50551\n1.49762\n1.4887\n1.4786\n1.46721\n⋯\n\n\n4\n1/02/2018.3\n1\n2.40688\n2.40424\n2.3992\n2.39114\n2.38054\n2.36857\n2.35634\n2.34405\n2.33153\n2.31797\n2.30259\n2.28396\n2.26211\n2.23634\n2.20659\n2.17255\n2.1348\n2.09384\n2.05097\n2.00741\n1.96439\n1.9222\n1.88192\n1.8439\n1.80882\n1.77683\n1.74832\n1.72348\n1.70202\n1.68354\n1.66778\n1.65442\n1.64315\n1.63344\n1.62511\n1.61791\n1.61168\n1.6062\n1.60137\n1.59691\n1.59266\n1.58823\n1.58372\n1.57906\n1.57448\n1.57023\n1.56651\n1.5632\n1.56034\n1.5578\n1.55561\n1.55371\n1.55202\n1.55071\n1.54959\n1.54857\n1.54776\n1.54717\n1.54693\n1.54715\n1.54776\n1.54868\n1.54974\n1.55077\n1.55177\n1.55282\n1.5539\n1.55508\n1.55643\n1.55789\n1.55934\n1.56085\n1.56242\n1.5641\n1.56577\n1.56717\n1.56826\n1.56873\n1.56832\n1.56701\n1.56485\n1.56201\n1.55865\n1.55508\n1.55154\n1.54815\n1.54492\n1.54169\n1.53825\n1.53445\n1.53002\n1.52496\n1.51904\n1.51225\n1.50436\n1.49529\n1.48484\n1.4731\n⋯\n\n\n5\n1/02/2018.4\n1\n2.40988\n2.40702\n2.40131\n2.39267\n2.38137\n2.3686\n2.35552\n2.34279\n2.33123\n2.31932\n2.30561\n2.2889\n2.26787\n2.2421\n2.21174\n2.17669\n2.13787\n2.09599\n2.05236\n2.00855\n1.96539\n1.92386\n1.88469\n1.8481\n1.8141\n1.7832\n1.75517\n1.73034\n1.70849\n1.68946\n1.67313\n1.65908\n1.64709\n1.63696\n1.62814\n1.62052\n1.61401\n1.60831\n1.60316\n1.59844\n1.59383\n1.58932\n1.58481\n1.58043\n1.57648\n1.5729\n1.56975\n1.56697\n1.56438\n1.56207\n1.55983\n1.55779\n1.55587\n1.55403\n1.55245\n1.55101\n1.55001\n1.54934\n1.54917\n1.54943\n1.55003\n1.55074\n1.55161\n1.55259\n1.55369\n1.55489\n1.55635\n1.55799\n1.55985\n1.56166\n1.56343\n1.56506\n1.56649\n1.56767\n1.56875\n1.56963\n1.57023\n1.57043\n1.57005\n1.56886\n1.5668\n1.56399\n1.56073\n1.55728\n1.55384\n1.5506\n1.5475\n1.54435\n1.54093\n1.53714\n1.53273\n1.52766\n1.52176\n1.51488\n1.50685\n1.49765\n1.4871\n1.4754\n⋯\n\n\n6\n1/02/2018.5\n1\n2.41301\n2.40883\n2.40207\n2.39301\n2.38192\n2.3696\n2.35745\n2.34573\n2.33416\n2.32167\n2.30738\n2.29006\n2.26895\n2.24357\n2.2135\n2.17873\n2.14003\n2.09796\n2.05414\n2.00975\n1.96631\n1.92457\n1.88492\n1.84771\n1.81349\n1.78226\n1.75422\n1.72938\n1.70785\n1.68903\n1.67271\n1.65854\n1.64646\n1.63629\n1.62765\n1.62037\n1.61428\n1.60889\n1.60399\n1.59937\n1.59488\n1.5905\n1.58611\n1.5818\n1.57775\n1.574\n1.57068\n1.56787\n1.56542\n1.56313\n1.56087\n1.5586\n1.55636\n1.55432\n1.55261\n1.55139\n1.55074\n1.55054\n1.55071\n1.5512\n1.55193\n1.55284\n1.5537\n1.55451\n1.55531\n1.55617\n1.55719\n1.55848\n1.56008\n1.56185\n1.56368\n1.56547\n1.56708\n1.56853\n1.56971\n1.57048\n1.57077\n1.57044\n1.5695\n1.56792\n1.56582\n1.56329\n1.56047\n1.55745\n1.55439\n1.55132\n1.54822\n1.5451\n1.5418\n1.53814\n1.53387\n1.5288\n1.5227\n1.51549\n1.50713\n1.49765\n1.4871\n1.47559\n⋯\n\n\n7\n1/02/2018.6\n1\n2.40641\n2.40349\n2.39797\n2.38992\n2.38015\n2.36888\n2.35759\n2.34651\n2.33515\n2.32307\n2.30805\n2.28966\n2.2676\n2.24119\n2.21044\n2.17569\n2.13769\n2.09721\n2.05494\n2.01232\n1.96999\n1.92859\n1.88879\n1.85133\n1.8168\n1.78529\n1.75702\n1.73198\n1.70977\n1.69017\n1.67324\n1.6588\n1.64666\n1.63655\n1.62831\n1.62153\n1.61571\n1.61056\n1.60576\n1.60113\n1.59645\n1.59176\n1.58711\n1.58259\n1.57825\n1.57422\n1.57056\n1.56745\n1.5647\n1.56239\n1.56036\n1.5586\n1.55699\n1.55556\n1.55429\n1.55326\n1.55243\n1.55185\n1.55151\n1.55142\n1.55162\n1.55213\n1.55282\n1.55369\n1.55468\n1.55573\n1.55686\n1.55801\n1.55935\n1.56087\n1.56248\n1.56415\n1.56581\n1.56742\n1.56888\n1.57012\n1.57099\n1.57136\n1.57103\n1.56992\n1.56795\n1.5652\n1.56196\n1.55846\n1.55487\n1.55144\n1.54811\n1.54484\n1.54135\n1.53737\n1.53277\n1.52733\n1.52102\n1.51383\n1.50565\n1.49659\n1.48648\n1.4752\n⋯\n\n\n8\n1/02/2018.7\n1\n2.4278\n2.42489\n2.41844\n2.40855\n2.39609\n2.38277\n2.36939\n2.35651\n2.34441\n2.332\n2.31786\n2.3007\n2.27974\n2.25444\n2.22436\n2.18974\n2.15133\n2.11012\n2.06702\n2.02315\n1.97941\n1.93685\n1.89622\n1.85839\n1.82365\n1.79251\n1.76464\n1.73988\n1.71781\n1.69842\n1.68132\n1.66653\n1.6539\n1.64351\n1.63479\n1.62743\n1.62106\n1.61564\n1.61066\n1.60609\n1.60173\n1.59747\n1.59319\n1.58896\n1.58479\n1.58104\n1.57754\n1.57448\n1.57177\n1.56929\n1.56706\n1.56498\n1.56301\n1.5613\n1.55984\n1.55873\n1.55806\n1.5578\n1.55791\n1.55823\n1.55859\n1.55902\n1.55944\n1.55994\n1.56061\n1.56164\n1.56284\n1.56424\n1.56578\n1.56741\n1.56896\n1.57053\n1.57196\n1.57334\n1.57449\n1.57548\n1.57627\n1.57669\n1.57657\n1.57572\n1.57406\n1.57161\n1.56856\n1.56518\n1.5617\n1.55831\n1.55514\n1.55193\n1.54862\n1.54487\n1.54056\n1.53546\n1.52935\n1.52219\n1.51388\n1.50435\n1.49367\n1.48189\n⋯\n\n\n9\n1/02/2018.8\n1\n2.42194\n2.41986\n2.41463\n2.40612\n2.39449\n2.38104\n2.36704\n2.35341\n2.34076\n2.32783\n2.31328\n2.29602\n2.27478\n2.249\n2.21866\n2.18395\n2.14595\n2.10522\n2.06285\n2.01992\n1.97736\n1.93597\n1.89647\n1.85912\n1.82464\n1.79299\n1.76446\n1.73911\n1.71686\n1.69767\n1.68129\n1.66719\n1.65516\n1.64478\n1.63576\n1.62793\n1.62099\n1.61492\n1.60952\n1.60462\n1.59992\n1.59544\n1.59109\n1.58695\n1.58292\n1.57925\n1.57604\n1.57333\n1.57106\n1.56922\n1.56744\n1.56569\n1.56369\n1.56163\n1.55952\n1.55765\n1.55628\n1.55547\n1.55526\n1.55571\n1.55655\n1.55777\n1.55904\n1.56036\n1.56152\n1.56262\n1.56373\n1.56496\n1.56632\n1.56796\n1.56968\n1.57151\n1.57318\n1.57476\n1.57598\n1.57686\n1.57719\n1.57697\n1.57615\n1.57472\n1.5726\n1.56997\n1.56695\n1.56371\n1.56039\n1.55709\n1.55388\n1.5506\n1.54703\n1.54299\n1.53845\n1.53312\n1.52699\n1.51989\n1.51186\n1.50277\n1.4925\n1.48114\n⋯\n\n\n10\n1/02/2018.9\n1\n2.41687\n2.41362\n2.40849\n2.40075\n2.39046\n2.3788\n2.36611\n2.35336\n2.34074\n2.32766\n2.31327\n2.29642\n2.27597\n2.25109\n2.22143\n2.18679\n2.14827\n2.10645\n2.06283\n2.01869\n1.97492\n1.93262\n1.89241\n1.85465\n1.8199\n1.78849\n1.76047\n1.73572\n1.71409\n1.69531\n1.67892\n1.66484\n1.65252\n1.642\n1.63334\n1.62609\n1.62003\n1.61474\n1.60988\n1.60518\n1.60024\n1.59516\n1.59032\n1.58553\n1.58124\n1.57738\n1.57402\n1.57115\n1.56865\n1.56637\n1.56438\n1.56237\n1.56057\n1.55891\n1.5575\n1.5563\n1.55552\n1.5551\n1.55519\n1.55554\n1.55627\n1.55717\n1.55807\n1.55902\n1.56004\n1.56105\n1.56217\n1.56343\n1.56486\n1.5664\n1.56796\n1.5696\n1.57116\n1.57254\n1.57365\n1.57435\n1.57455\n1.57424\n1.57335\n1.57196\n1.57\n1.56758\n1.56468\n1.56147\n1.55813\n1.55485\n1.55163\n1.54842\n1.545\n1.54126\n1.53686\n1.53182\n1.52588\n1.51902\n1.51112\n1.50201\n1.49159\n1.47983\n⋯\n\n\n\n\n\n\n\n\n2.2 corece and split data\n\n\nCode\n to_ScienceType(d)=coerce(d,:labels=&gt;Multiclass)\n df=to_ScienceType(df)\n ytrain, Xtrain=  unpack(df, ==(:labels),!=(:Column1), rng=123);\n cat=ytrain|&gt;levels\n rows,cols=size(Xtrain)\n\n\n(450, 601)"
  },
  {
    "objectID": "category/dimension-reduction/4-NIR-Spectra-Milk.html#workflow",
    "href": "category/dimension-reduction/4-NIR-Spectra-Milk.html#workflow",
    "title": "4-NIR-Spectra-Milk",
    "section": "3 workflow",
    "text": "3 workflow\n\n3.1 instantate model and train model\n\n\nCode\n    SVC = @load SVC pkg=LIBSVM \n    PCA = @load PCA pkg=MultivariateStats\n    maxdim=2;nums=200\n    model1=PCA(;maxoutdim=maxdim)\n    model2 = SVC()\n    mach1 = machine(model1, Xtrain) |&gt; fit!\n    Ytr =transform(mach1, Xtrain)\n    mach2 = machine(model2, Ytr, ytrain)|&gt;fit!\n    Yte=transform(mach1, Xtrain)\n    tx,ty,x_test=boundary_data2(Yte)\n    yhat = predict(mach2, x_test)|&gt;Array|&gt;d-&gt;reshape(d,nums,nums)\n\n\nimport MLJLIBSVMInterface ✔\nimport MLJMultivariateStatsInterface ✔\n\n\n[ Info: For silent loading, specify `verbosity=0`. \n[ Info: For silent loading, specify `verbosity=0`. \n[ Info: Training machine(PCA(maxoutdim = 2, …), …).\n[ Info: Training machine(SVC(kernel = RadialBasis, …), …).\n\n\n200×200 Matrix{Int64}:\n 1  1  1  1  1  1  1  1  1  1  1  1  1  …  5  5  5  5  5  5  5  5  5  5  5  5\n 1  1  1  1  1  1  1  1  1  1  1  1  1     5  5  5  5  5  5  5  5  5  5  5  5\n 1  1  1  1  1  1  1  1  1  1  1  1  1     5  5  5  5  5  5  5  5  5  5  5  5\n 1  1  1  1  1  1  1  1  1  1  1  1  1     5  5  5  5  5  5  5  5  5  5  5  5\n 1  1  1  1  1  1  1  1  1  1  1  1  1     5  5  5  5  5  5  5  5  5  5  5  5\n 1  1  1  1  1  1  1  1  1  1  1  1  1  …  5  5  5  5  5  5  5  5  5  5  5  5\n 1  1  1  1  1  1  1  1  1  1  1  1  1     5  5  5  5  5  5  5  5  5  5  5  5\n 1  1  1  1  1  1  1  1  1  1  1  1  1     5  5  5  5  5  9  9  9  9  9  9  9\n 1  1  1  1  1  1  1  1  1  1  1  1  1     9  9  9  9  9  9  9  9  9  9  9  9\n 1  1  1  1  1  1  1  1  1  1  1  1  1     9  9  9  9  9  9  9  9  9  9  9  9\n 1  1  1  1  1  1  1  1  1  1  1  1  1  …  9  9  9  9  9  9  9  9  9  9  9  9\n 1  1  1  1  1  1  1  1  1  1  1  1  1     9  9  9  9  9  9  9  9  9  9  9  9\n 1  1  1  1  1  1  1  1  1  1  1  1  1     9  9  9  9  9  9  9  9  9  9  9  9\n ⋮              ⋮              ⋮        ⋱        ⋮              ⋮           \n 2  2  2  2  2  2  2  2  2  2  2  2  2     6  6  6  6  6  6  6  6  6  6  6  6\n 2  2  2  2  2  2  2  2  2  2  2  2  2     6  6  6  6  6  6  6  6  6  6  6  6\n 2  2  2  2  2  2  2  2  2  2  2  2  2  …  6  6  6  6  6  6  6  6  6  6  6  6\n 2  2  2  2  2  2  2  2  2  2  2  2  2     6  6  6  6  6  6  6  6  6  6  6  6\n 2  2  2  2  2  2  2  2  2  2  2  2  2     6  6  6  6  6  6  6  6  6  6  6  6\n 2  2  2  2  2  2  2  2  2  2  2  2  2     6  6  6  6  6  6  6  6  6  6  6  6\n 2  2  2  2  2  2  2  2  2  2  2  2  2     6  6  6  6  6  6  6  6  6  6  6  6\n 2  2  2  2  2  2  2  2  2  2  2  2  2  …  6  6  6  6  6  6  6  6  6  6  6  6\n 2  2  2  2  2  2  2  2  2  2  2  2  2     6  6  6  6  6  6  6  6  6  6  6  6\n 2  2  2  2  2  2  2  2  2  2  2  2  2     6  6  6  6  6  6  6  6  6  6  6  6\n 2  2  2  2  2  2  2  2  2  2  2  2  2     6  6  6  6  6  6  6  6  6  6  6  6\n 2  2  2  2  2  2  2  2  2  2  2  2  2     6  6  6  6  6  6  6  6  6  6  6  6\n\n\n\n\n3.2 plot 2d results\n\n\nCode\nfunction plot_data()\n    \n    fig=Figure(resolution=(800,800))\n    ax= maxdim==3 ? Axis3(fig[1,1]) : Axis(fig[1,1])\n    colors=[:red, :yellow,:purple,:lightblue,:black,:orange,:pink,:blue,:tomato]\n    contourf!(ax,tx,ty,yhat,levels=length(cat),colormap=:redsblues)\n    for (c,color) in zip(cat,colors)\n        data=Ytr[ytrain.==c,:]\n        if maxdim==3\n            scatter!(ax,data[:,1], data[:,2],data[:,3],color=(color,0.8),markersize=14)\n        elseif maxdim==2\n            scatter!(ax,data[:,1], data[:,2],color=(color,0.8),markersize=14)\n        else\n            return nothing\n        end\n    end\n    fig\nend\nplot_data()\n\n\n\n\n\n\n\n3.3 to 3d dimension\n\n\nCode\n  let\n    maxdim=3;nums=200\n    model1=PCA(;maxoutdim=maxdim)\n    model2 = SVC()\n    mach1 = machine(model1, Xtrain) |&gt; fit!\n    Ytr =transform(mach1, Xtrain)\n    mach2 = machine(model2, Ytr, ytrain)|&gt;fit!\n    Yte=transform(mach1, Xtrain)\n    fig=Figure(resolution=(800,800))\n    ax= maxdim==3 ? Axis3(fig[1,1]) : Axis(fig[1,1])\n    colors=[:red, :yellow,:purple,:lightblue,:black,:orange,:pink,:blue,:tomato]\n    \n    for (c,color) in zip(cat,colors)\n        data=Ytr[ytrain.==c,:]\n        if maxdim==3\n            scatter!(ax,data[:,1], data[:,2],data[:,3],color=(color,0.8),markersize=14;label=c)\n        elseif maxdim==2\n            scatter!(ax,data[:,1], data[:,2],color=(color,0.8),markersize=14;label=c)\n        else\n            return nothing\n        end\n    end\n    \n    fig\nend\n\n\n[ Info: Training machine(PCA(maxoutdim = 3, …), …).\n[ Info: Training machine(SVC(kernel = RadialBasis, …), …)."
  },
  {
    "objectID": "category/schedule.html",
    "href": "category/schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Example schedule:\n\n\n\n\n\n\n\n\n\nMorning\nAfternoon\n\n\n\n\nL\nIntro + Data manipulation\ngit / GitHub\n\n\nM\nGeneralised Linear Models\nData visualisation\n\n\nX\nMixed models / GAM / Bayes\nFunctional programming + Students work\n\n\nJ\nMultivariate analyses\nReproducible workflows\n\n\nV\nUsing R as GIS + Students work\nProject presentations"
  },
  {
    "objectID": "category/dataset/index.html",
    "href": "category/dataset/index.html",
    "title": "dataset index list",
    "section": "",
    "text": "“intor of dataset”\n1"
  }
]